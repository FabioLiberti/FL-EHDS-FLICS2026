# FL-EHDS Framework Configuration
# =================================
# Configuration for Privacy-Preserving Federated Learning
# under European Health Data Space (EHDS) Regulation

framework:
  name: "FL-EHDS"
  version: "1.0.0"
  environment: "development"  # development, staging, production
  log_level: "INFO"

# =============================================================================
# LAYER 1: GOVERNANCE
# =============================================================================
governance:
  # Health Data Access Body Integration
  hdab:
    # API endpoint for HDAB communication
    endpoint: "https://hdab.healthdata.eu/api/v1"
    # Authentication method: api_key, oauth2, mtls
    auth_method: "oauth2"
    # Request timeout in seconds
    timeout: 30
    # Retry configuration
    retry:
      max_attempts: 3
      backoff_factor: 2
    # Cache settings for permit validation
    cache:
      enabled: true
      ttl_seconds: 3600  # 1 hour

  # Data Permit Management
  permits:
    # Permitted purposes per EHDS Article 53
    allowed_purposes:
      - "scientific_research"
      - "public_health_surveillance"
      - "health_policy"
      - "education_training"
      - "ai_system_development"
      - "personalized_medicine"
    # Data categories that can be processed
    data_categories:
      - "ehr"           # Electronic Health Records
      - "lab_results"   # Laboratory data
      - "imaging"       # Medical imaging
      - "genomic"       # Genetic data
      - "registry"      # Disease registries
    # Permit validation settings
    validation:
      strict_mode: true
      verify_expiry: true
      check_purpose_alignment: true

  # Opt-out Registry (Article 71)
  optout:
    # Sync interval with national registries (seconds)
    sync_interval: 300  # 5 minutes
    # Cache configuration
    cache:
      enabled: true
      max_size: 100000  # Maximum cached records
      ttl_seconds: 600  # 10 minutes
    # Opt-out checking granularity
    granularity: "record"  # record, patient, dataset
    # Action on opt-out detection
    on_optout: "exclude"  # exclude, anonymize, error

  # Training Integration (permit-aware training)
  training_integration:
    enabled: false  # Default off for backward compatibility
    default_purpose: "ai_system_development"
    default_privacy_budget: 100.0
    data_minimization:
      enabled: false
      importance_threshold: 0.01
      method: "mutual_info"  # mutual_info or variance

  # Compliance Logging (GDPR Article 30)
  logging:
    # Log storage backend
    backend: "structured_file"  # structured_file, database, siem
    # Log file path (for file backend)
    path: "logs/compliance/"
    # Retention period in days
    retention_days: 2555  # ~7 years per GDPR
    # Log format
    format: "json"
    # Fields to always include
    required_fields:
      - "timestamp"
      - "action"
      - "actor"
      - "data_categories"
      - "purpose"
      - "legal_basis"
      - "outcome"

# =============================================================================
# LAYER 2: FL ORCHESTRATION
# =============================================================================
orchestration:
  # Aggregation Configuration
  aggregation:
    # Algorithm selection: fedavg, fedprox, scaffold
    algorithm: "fedavg"

    # FedAvg specific settings
    fedavg:
      weighted: true  # Weight by dataset size

    # FedProx specific settings (for non-IID data)
    fedprox:
      mu: 0.01  # Proximal term coefficient

    # Training rounds
    num_rounds: 100
    # Minimum clients per round
    min_clients: 3
    # Maximum clients per round (null = all available)
    max_clients: null
    # Client selection strategy: random, performance, fairness
    client_selection: "random"
    # Early stopping
    early_stopping:
      enabled: true
      patience: 10
      min_delta: 0.001

  # Privacy Protection
  privacy:
    # Differential Privacy
    differential_privacy:
      enabled: true
      # Privacy budget (lower = more private)
      epsilon: 1.0
      # Failure probability
      delta: 1e-5
      # Noise mechanism: gaussian, laplace
      mechanism: "gaussian"
      # Accountant type: rdp, gdp, prv
      accountant: "rdp"
      # Maximum gradient norm for sensitivity
      max_grad_norm: 1.0

    # Gradient Clipping
    gradient_clipping:
      enabled: true
      # Clipping norm
      max_norm: 1.0
      # Clipping type: l2, linf
      norm_type: "l2"
      # Per-layer or global clipping
      per_layer: false

    # Secure Aggregation
    secure_aggregation:
      enabled: true
      # Protocol: shamir, paillier, functional_encryption
      protocol: "shamir"
      # Threshold for secret reconstruction
      threshold: 0.67  # 2/3 of clients
      # Key management
      key_rotation_rounds: 10

  # Compliance Module
  compliance:
    # Purpose Limitation (Article 53)
    purpose_limitation:
      enabled: true
      # Enforce at training start
      verify_on_init: true
      # Verify each round
      verify_per_round: false
      # Actions on violation
      on_violation: "abort"  # abort, warn, log

    # Model Output Controls
    output_controls:
      # Minimum aggregation threshold
      min_aggregation_count: 5
      # Output anonymization
      anonymize_outputs: true
      # Model inspection restrictions
      allow_gradient_inspection: false

# =============================================================================
# LAYER 3: DATA HOLDERS
# =============================================================================
data_holders:
  # Training Engine Configuration
  training:
    # Model architecture settings
    model:
      # Default architecture type
      type: "neural_network"
      # Architecture file (optional)
      architecture_path: null

    # Training hyperparameters
    hyperparameters:
      batch_size: 32
      local_epochs: 5
      learning_rate: 0.01
      optimizer: "sgd"  # sgd, adam, adamw
      momentum: 0.9
      weight_decay: 1e-4

    # Adaptive training for hardware heterogeneity
    adaptive:
      enabled: true
      # Adjust batch size based on memory
      adaptive_batching: true
      # Minimum batch size
      min_batch_size: 8
      # Maximum batch size
      max_batch_size: 128
      # Model partitioning for limited resources
      model_partitioning: false
      # Gradient accumulation steps
      gradient_accumulation: 1

  # FHIR Preprocessing
  preprocessing:
    # FHIR version
    fhir_version: "R4"
    # Validation settings
    validation:
      enabled: true
      strict: false
    # Normalization
    normalize: true
    # Missing value handling
    missing_values:
      strategy: "impute"  # impute, drop, error
      imputation_method: "median"  # mean, median, mode, constant
    # Feature engineering
    features:
      # Categorical encoding
      categorical_encoding: "onehot"  # onehot, label, target
      # Numerical scaling
      numerical_scaling: "standard"  # standard, minmax, robust
    # Resource type mappings
    resource_mappings:
      Patient: ["demographics", "identifiers"]
      Observation: ["lab_results", "vitals"]
      Condition: ["diagnoses"]
      Procedure: ["interventions"]
      MedicationRequest: ["prescriptions"]

  # Secure Communication
  communication:
    # Transport protocol
    protocol: "grpc"  # grpc, https, websocket
    # Encryption
    encryption:
      enabled: true
      algorithm: "AES-256-GCM"
      key_exchange: "ECDHE"
    # Authentication
    authentication:
      method: "mtls"  # mtls, jwt, api_key
      certificate_path: "certs/"
    # Compression
    compression:
      enabled: true
      algorithm: "gzip"
      level: 6
    # Timeout settings
    timeout:
      connect: 10
      read: 60
      write: 60
    # Retry policy
    retry:
      max_attempts: 3
      backoff_base: 1.0
      backoff_max: 30.0

# =============================================================================
# MONITORING & OBSERVABILITY
# =============================================================================
monitoring:
  # Metrics collection
  metrics:
    enabled: true
    # Export format: prometheus, statsd, otlp
    exporter: "prometheus"
    # Export endpoint
    endpoint: "localhost:9090"
    # Collection interval (seconds)
    interval: 15

  # Health checks
  health:
    enabled: true
    endpoint: "/health"
    checks:
      - "hdab_connectivity"
      - "storage_available"
      - "memory_usage"

  # Alerting
  alerting:
    enabled: false
    # Alert destinations
    destinations: []

# =============================================================================
# TRAINING EXPERIMENT DEFAULTS
# =============================================================================
# Suggested defaults loaded by both Terminal CLI and Web Dashboard.
# Each interface allows interactive override of any value at runtime.
# Environment variables FL_EHDS_* take highest precedence over YAML values.
# These values reflect the conservative terminal defaults.

training:
  # Random seed for reproducibility
  seed: 42

  # Federated learning parameters
  federated:
    # Algorithm: FedAvg, FedProx, SCAFFOLD, FedNova, FedDyn,
    #            FedAdam, FedYogi, FedAdagrad, Per-FedAvg, Ditto
    algorithm: "FedAvg"
    # Number of hospitals/nodes (2-100)
    num_clients: 5
    # Communication rounds (1-1000)
    num_rounds: 30
    # Local training epochs per round (1-50)
    local_epochs: 3
    # Mini-batch size (1-512)
    batch_size: 32
    # Client-side learning rate (0.0001-1.0)
    learning_rate: 0.01
    # Proximal term for FedProx / regularization for Ditto (0.0-1.0)
    mu: 0.1

    # Server-side optimizer parameters (FedAdam, FedYogi, FedAdagrad)
    server_optimizer:
      lr: 0.1
      beta1: 0.9
      beta2: 0.99
      tau: 0.001

  # Differential privacy configuration
  privacy:
    # Enable DP noise injection during training
    enabled: false
    # Privacy budget epsilon (0.1-100, lower = more private)
    epsilon: 10.0
    # Failure probability delta
    delta: 1.0e-5
    # Maximum gradient norm for sensitivity bounding
    clip_norm: 1.0

  # Data configuration
  data:
    # Dataset type: "synthetic" (generated tabular) or "imaging" (clinical images)
    type: "synthetic"
    # Path to imaging dataset root (null = auto-discover from data/ directory)
    path: null
    # Data distribution: "iid" or "non_iid"
    distribution: "non_iid"
    # Dirichlet alpha for non-IID partitioning (0.1-10.0, lower = more skewed)
    alpha: 0.5
    # Image resize dimension for imaging datasets (32, 64, 128, 224)
    img_size: 128

# =============================================================================
# CROSS-BORDER FEDERATION (EHDS)
# =============================================================================
# Configuration for cross-border federated learning across EU member states.
# Each country enforces its national privacy ceiling (dp_epsilon_max) and
# HDAB policies on top of the global training parameters above.

cross_border:
  # Default country selection (ISO 3166-1 alpha-2)
  # Available: DE, FR, IT, ES, NL, SE, PL, AT, BE, PT
  countries: ["DE", "FR", "IT", "ES", "NL"]
  # Number of hospitals per country (1-3)
  hospitals_per_country: 1
  # EHDS Article 53 purpose for the experiment
  # Options: scientific_research, public_health_surveillance, health_policy,
  #          education_training, ai_system_development, personalized_medicine
  purpose: "scientific_research"
  # Simulate inter-country network latency
  simulate_latency: true
  # Global epsilon ceiling (per-country may be lower)
  global_epsilon: 10.0

  # Per-jurisdiction privacy budget enforcement
  # Each country's HDAB sets a national epsilon ceiling. Hospitals within a
  # country cannot exceed this ceiling. When a hospital exhausts its budget,
  # it stops participating but training continues with remaining clients.
  jurisdiction_privacy:
    enabled: false                     # Off by default (backward compatible)
    noise_strategy: "global"           # "global" = strictest active client calibrates noise
    accountant_type: "rdp"             # Uses existing RDP PrivacyAccountant
    hospital_allocation_fraction: 1.0  # Fraction of national ceiling per hospital
    min_active_clients: 2              # Minimum clients to continue training
    # Per-country epsilon overrides (if omitted, uses EU_COUNTRY_PROFILES defaults)
    country_overrides: {}
    # Example:
    # country_overrides:
    #   DE: {epsilon_max: 1.0, delta: 1e-6}
    #   IT: {epsilon_max: 5.0, delta: 1e-5}

  # IHE Integration Profiles for FL
  # Maps standard IHE profiles (ATNA, XDS-I.b, CT, XUA, BPPC) to FL operations
  # for EHDS compliance. See governance/ihe_fl_bridge.py for implementation.
  ihe:
    enabled: false                     # Off by default (backward compatible)
    atna_audit: true                   # ATNA audit trail per FL round
    xds_imaging_simulation: true       # XDS-I.b DICOM retrieve simulation
    consistent_time: true              # CT profile: NTP sync simulation
    mtls_simulation: true              # mTLS between FL nodes
    xua_authentication: true           # XUA SAML assertion per session
    bppc_consent_check: true           # BPPC consent verification
    # NTP server for CT profile (simulated)
    ntp_server: "ntp.ehds.europa.eu"
    max_clock_drift_ms: 50             # Max tolerated drift between nodes (ms)
    # Certificate simulation
    certificate_authority: "EHDS-CA"
    certificate_validity_days: 365

  # Data Quality Framework (EHDS Art. 69)
  # Quality-weighted aggregation and pre-training anomaly detection.
  # Each client's data is scored on 5 quality dimensions. The quality
  # score modifies the aggregation weight: w_h = (n_h/N) * q_h^alpha.
  data_quality:
    enabled: false                     # Off by default (backward compatible)
    # Alpha: exponent for quality weight (0=ignore, 1=linear, 2=strong)
    alpha: 1.0
    # Dimension weights (must sum to 1.0)
    weight_completeness: 0.20
    weight_accuracy: 0.25
    weight_uniqueness: 0.15
    weight_diversity: 0.20
    weight_consistency: 0.20
    # EHDS Art. 69 quality label thresholds
    gold_threshold: 0.85
    silver_threshold: 0.70
    bronze_threshold: 0.55
    # Anomaly detection thresholds
    ks_threshold: 0.05                 # KS test p-value for distribution shift
    missing_threshold: 0.30            # Max fraction of missing values before anomaly
    entropy_threshold: 0.30            # Min normalized class entropy
    iqr_multiplier: 3.0                # IQR multiplier for outlier detection

# =============================================================================
# FHIR R4 DATA PIPELINE
# =============================================================================
# Configuration for FHIR-native data loading.
# Generates realistic non-IID data through hospital specialization profiles.
# Each profile creates a distinct patient demographic (natural non-IID).

fhir:
  # Default hospital profiles for synthetic FHIR generation
  # Available: general, cardiac, pediatric, geriatric, oncology
  default_profiles: ["general", "cardiac", "pediatric", "geriatric", "oncology"]
  # Patients per hospital/client
  samples_per_client: 500
  # Feature specification (maps to FHIR PatientRecord fields)
  feature_spec:
    - "age"
    - "gender"
    - "bmi"
    - "systolic_bp"
    - "diastolic_bp"
    - "heart_rate"
    - "glucose"
    - "cholesterol"
    - "num_conditions"
    - "num_medications"
  # Label for binary classification
  # Options: mortality_30day, readmission, icu_admission
  label: "mortality_30day"
  # EHDS Article 71 opt-out settings
  opt_out:
    # Path to opt-out registry JSON file (null = no opt-out filtering)
    registry_path: null
    # EHDS purpose for data access
    purpose: "ai_training"

# =============================================================================
# OMOP-CDM HARMONIZATION
# =============================================================================
# Cross-border vocabulary harmonization via OMOP Common Data Model.
# Maps local coding systems (ICD-10-GM, CIM-10, ICD-9-CM, etc.) to standard
# OMOP/SNOMED concept IDs for federated learning across EU hospitals.
omop:
  # EU country codes for cross-border simulation
  country_codes: ["DE", "FR", "IT", "ES", "NL"]
  # Hospital clinical profiles (same as FHIR)
  profiles: ["general", "cardiac", "pediatric", "geriatric", "oncology"]
  # Patients per hospital
  samples_per_client: 500
  # Feature extraction settings
  features:
    # Normalization method (zscore or minmax)
    normalization: "zscore"
    # Enable temporal window features (30d/90d/365d)
    temporal_windows: true
  # Target label
  label: "mortality_30day"
  # Vocabulary heterogeneity metrics
  heterogeneity:
    compute_jaccard: true
    compute_jsd: true

# =============================================================================
# ALGORITHM PROFILES
# =============================================================================
# Recommended hyperparameters for each FL algorithm.
# Suggested by terminal interface after algorithm selection.
# Users can accept or override any value during configuration.

algorithm_profiles:
  FedAvg:
    description: "Baseline averaging - buono per dati IID"
    learning_rate: 0.01
    learning_rate_imaging: 0.001
    local_epochs: 3
    num_rounds: 30
    batch_size: 32
    recommended_for: ["iid", "baseline", "primo_esperimento"]

  FedProx:
    description: "Termine prossimale - robusto a dati non-IID"
    learning_rate: 0.01
    learning_rate_imaging: 0.001
    local_epochs: 5
    num_rounds: 40
    batch_size: 32
    mu: 0.1
    recommended_for: ["non_iid", "eterogeneo"]

  SCAFFOLD:
    description: "Control variate - riduce drift tra client"
    learning_rate: 0.005
    learning_rate_imaging: 0.0005
    local_epochs: 3
    num_rounds: 50
    batch_size: 64
    recommended_for: ["non_iid_forte", "molti_client"]

  FedNova:
    description: "Averaging normalizzato - hardware eterogeneo"
    learning_rate: 0.01
    learning_rate_imaging: 0.001
    local_epochs: 2
    num_rounds: 30
    batch_size: 32
    recommended_for: ["hardware_eterogeneo", "risorse_limitate"]

  FedDyn:
    description: "Regolarizzazione dinamica - convergenza veloce non-IID"
    learning_rate: 0.01
    learning_rate_imaging: 0.001
    local_epochs: 5
    num_rounds: 40
    batch_size: 32
    alpha_dyn: 0.01
    recommended_for: ["non_iid", "convergenza"]

  FedAdam:
    description: "Server-side Adam - convergenza rapida"
    learning_rate: 0.01
    learning_rate_imaging: 0.001
    local_epochs: 5
    num_rounds: 30
    batch_size: 32
    server_lr: 0.1
    beta1: 0.9
    beta2: 0.99
    tau: 0.001
    recommended_for: ["convergenza_rapida", "loss_complesso"]

  FedYogi:
    description: "Server-side Yogi - piu conservativo di FedAdam"
    learning_rate: 0.01
    learning_rate_imaging: 0.001
    local_epochs: 5
    num_rounds: 40
    batch_size: 32
    server_lr: 0.05
    beta1: 0.9
    beta2: 0.99
    tau: 0.001
    recommended_for: ["convergenza_stabile", "outlier"]

  FedAdagrad:
    description: "Server-side Adagrad - LR adattivo decrescente"
    learning_rate: 0.01
    learning_rate_imaging: 0.001
    local_epochs: 3
    num_rounds: 50
    batch_size: 32
    server_lr: 0.1
    tau: 0.01
    recommended_for: ["features_sparse", "categoriche"]

  Per-FedAvg:
    description: "Meta-learning per personalizzazione locale"
    learning_rate: 0.01
    learning_rate_imaging: 0.001
    local_epochs: 3
    num_rounds: 50
    batch_size: 32
    recommended_for: ["personalizzazione", "meta_learning"]

  Ditto:
    description: "Personalizzazione con regolarizzazione L2 vs globale"
    learning_rate: 0.01
    learning_rate_imaging: 0.001
    local_epochs: 5
    num_rounds: 40
    batch_size: 32
    mu: 0.5
    recommended_for: ["personalizzazione", "modelli_locali"]

# =============================================================================
# CLINICAL USE CASE PROFILES
# =============================================================================
# Pre-configured scenarios for healthcare applications.
# Maps clinical use cases to recommended algorithms and parameters.
# Used by the Guided Comparison screen (Menu 3).

clinical_use_cases:
  multi_hospital_iid:
    name: "Collaborazione Multi-Ospedale (Popolazioni Simili)"
    description: "Ospedali con demografie simili collaborano su modello comune"
    data_characteristics: "IID o near-IID"
    recommended_algorithms: ["FedAvg", "FedAdam", "FedYogi"]
    parameters:
      is_iid: true
      alpha: 10.0
      num_rounds: 30
      local_epochs: 3
    rationale: "Con distribuzioni simili, algoritmi semplici funzionano bene. FedAdam/FedYogi accelerano la convergenza."

  rare_disease:
    name: "Malattie Rare (Dati Eterogenei)"
    description: "Studio malattie rare con sottopopolazioni diverse per centro"
    data_characteristics: "Fortemente non-IID, label skew"
    recommended_algorithms: ["SCAFFOLD", "FedProx", "FedNova"]
    parameters:
      is_iid: false
      alpha: 0.3
      num_rounds: 50
      local_epochs: 5
      mu: 0.1
    rationale: "Dati non-IID richiedono correzione del drift. SCAFFOLD usa control variate, FedProx regolarizzazione."

  personalized_medicine:
    name: "Medicina Personalizzata"
    description: "Modelli di rischio personalizzati con apprendimento collaborativo"
    data_characteristics: "Ogni ospedale necessita modello su misura"
    recommended_algorithms: ["Ditto", "Per-FedAvg", "FedProx"]
    parameters:
      is_iid: false
      alpha: 0.5
      num_rounds: 40
      local_epochs: 3
      mu: 0.5
    rationale: "Ditto e Per-FedAvg mantengono modelli client-specifici imparando dal globale."

  resource_constrained:
    name: "Dispositivi con Risorse Limitate (IoT/Edge)"
    description: "Training su dispositivi con capacita computazionale variabile"
    data_characteristics: "Calcolo eterogeneo, epoche locali variabili"
    recommended_algorithms: ["FedNova", "FedAvg", "FedProx"]
    parameters:
      is_iid: false
      alpha: 1.0
      num_rounds: 30
      local_epochs: 2
    rationale: "FedNova normalizza gli aggiornamenti per calcolo eterogeneo."

  privacy_critical:
    name: "Privacy Critica (Garanzie DP Forti)"
    description: "Scenari con DP forte (es. dati salute mentale)"
    data_characteristics: "Requisiti privacy stringenti, epsilon < 5"
    recommended_algorithms: ["FedAvg", "FedProx"]
    parameters:
      is_iid: false
      alpha: 0.5
      num_rounds: 30
      local_epochs: 1
      dp_enabled: true
      dp_epsilon: 1.0
      dp_clip_norm: 1.0
    rationale: "Aggregazione semplice funziona meglio con DP. Meno epoche locali riducono il budget privacy."

  cross_border_ehds:
    name: "Cross-Border EHDS"
    description: "Collaborazione pan-europea sotto regolamento EHDS"
    data_characteristics: "Alta eterogeneita, compliance normativa"
    recommended_algorithms: ["SCAFFOLD", "FedProx", "Ditto"]
    parameters:
      is_iid: false
      alpha: 0.5
      num_rounds: 50
      local_epochs: 3
      mu: 0.1
      dp_enabled: true
      dp_epsilon: 10.0
    rationale: "Dati cross-border naturalmente eterogenei. SCAFFOLD gestisce il drift. DP per compliance GDPR."

  fast_convergence:
    name: "Convergenza Rapida (Emergenze)"
    description: "Scenari time-critical come risposta pandemica"
    data_characteristics: "Convergenza rapida necessaria"
    recommended_algorithms: ["FedAdam", "FedYogi", "SCAFFOLD"]
    parameters:
      is_iid: false
      alpha: 1.0
      num_rounds: 20
      local_epochs: 5
      server_lr: 0.1
      beta1: 0.9
      beta2: 0.99
    rationale: "Ottimizzatori server adattivi accelerano la convergenza. Piu epoche per round riducono i round necessari."

# =============================================================================
# DATASET-SPECIFIC PARAMETERS
# =============================================================================
# Optimal parameters per dataset based on empirical results.
# Extended to all 6 imaging datasets + synthetic tabular.
# Displayed in terminal (Menu 4 > Tabella Parametri) and dashboard sidebar.

dataset_parameters:
  synthetic_healthcare:
    type: "tabular"
    img_size: null
    learning_rate: 0.01
    batch_size: 32
    num_rounds: 30
    local_epochs: 3
    alpha: 0.5
    class_weight: false
    recommended_algorithms: ["FedAvg", "FedProx", "SCAFFOLD"]
    notes: "Dataset sintetico per test e prototipazione algoritmi"

  fhir_synthetic:
    type: "tabular"
    img_size: null
    learning_rate: 0.01
    batch_size: 32
    num_rounds: 30
    local_epochs: 3
    alpha: null
    class_weight: false
    recommended_algorithms: ["FedAvg", "FedProx", "SCAFFOLD", "Ditto"]
    notes: "Dati FHIR R4 sintetici - non-IID naturale da profili ospedalieri"

  omop_harmonized:
    type: "tabular"
    img_size: null
    learning_rate: 0.01
    batch_size: 32
    num_rounds: 30
    local_epochs: 3
    alpha: null
    class_weight: false
    recommended_algorithms: ["SCAFFOLD", "FedProx", "Ditto", "FedAvg"]
    notes: "OMOP-CDM armonizzato - ~36 features, non-IID da eterogeneita vocabolario cross-border"

  Retinopatia:
    type: "imaging"
    img_size: 224
    learning_rate: 0.0005
    batch_size: 16
    num_rounds: 50
    local_epochs: 3
    alpha: 0.5
    class_weight: true
    recommended_algorithms: ["FedAvg", "FedAdam", "SCAFFOLD"]
    notes: "35K immagini, 5 stadi DR, forte sbilanciamento - usare class_weight"

  Brain_Tumor:
    type: "imaging"
    img_size: 128
    learning_rate: 0.001
    batch_size: 32
    num_rounds: 40
    local_epochs: 3
    alpha: 0.3
    class_weight: false
    recommended_algorithms: ["FedProx", "SCAFFOLD", "Ditto"]
    notes: "7K immagini, 4 classi MRI, bilanciato"

  chest_xray:
    type: "imaging"
    img_size: 224
    learning_rate: 0.0005
    batch_size: 16
    num_rounds: 30
    local_epochs: 2
    alpha: 0.5
    class_weight: true
    recommended_algorithms: ["FedAvg", "FedAdam"]
    notes: "6K immagini, binario (NORMAL/PNEUMONIA), sbilanciamento 73/27"

  "Skin Cancer":
    type: "imaging"
    img_size: 128
    learning_rate: 0.001
    batch_size: 32
    num_rounds: 30
    local_epochs: 3
    alpha: 0.5
    class_weight: false
    recommended_algorithms: ["FedAvg", "FedProx"]
    notes: "3K immagini, binario (benigno/maligno), bilanciato"

  "Brain Tumor MRI":
    type: "imaging"
    img_size: 128
    learning_rate: 0.001
    batch_size: 32
    num_rounds: 40
    local_epochs: 3
    alpha: 0.3
    class_weight: false
    recommended_algorithms: ["FedProx", "SCAFFOLD"]
    notes: "3K immagini, 4 classi tumore, bilanciato"

  ISIC:
    type: "imaging"
    img_size: 128
    learning_rate: 0.0005
    batch_size: 16
    num_rounds: 50
    local_epochs: 3
    alpha: 0.3
    class_weight: true
    recommended_algorithms: ["SCAFFOLD", "FedProx", "Ditto"]
    notes: "2K immagini, 9 tipi lesione cutanea, forte sbilanciamento"

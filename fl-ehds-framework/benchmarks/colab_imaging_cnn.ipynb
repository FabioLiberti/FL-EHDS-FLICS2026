{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ_GcFx_ZJig"
      },
      "source": [
        "# FL-EHDS — HealthcareCNN Imaging Comparison\n",
        "\n",
        "Confronto HealthcareCNN (~500K params) vs ResNet-18 (11.2M params) su dataset imaging.\n",
        "\n",
        "- **27 esperimenti**: 3 algos × 3 datasets × 3 seeds\n",
        "- **Tempo stimato**: ~1.5-2.5 ore su GPU T4/A100\n",
        "- **Checkpoint**: salvataggio automatico ogni esperimento\n",
        "\n",
        "**IMPORTANTE**: Seleziona GPU runtime: Runtime → Change runtime type → GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "B1nDRCKnZJih",
        "outputId": "50be4d62-df02-45d0-e3c3-03a4e660322f"
      },
      "source": [
        "# === CELLA 1: Setup ===\n",
        "!git clone https://github.com/FabioLiberti/FL-EHDS-FLICS2026.git\n",
        "%cd FL-EHDS-FLICS2026/fl-ehds-framework\n",
        "!pip install -q opacus>=1.4.0 scikit-learn scipy tqdm rich pydantic pyyaml\n",
        "\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"ATTENZIONE: Nessuna GPU! Vai su Runtime -> Change runtime type -> GPU\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FL-EHDS-FLICS2026'...\n",
            "remote: Enumerating objects: 1709, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 1709 (delta 8), reused 6 (delta 4), pack-reused 1684 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1709/1709), 54.68 MiB | 22.86 MiB/s, done.\n",
            "Resolving deltas: 100% (959/959), done.\n",
            "/content/FL-EHDS-FLICS2026/fl-ehds-framework\n",
            "GPU: Tesla T4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'torch._C._CudaDeviceProperties' object has no attribute 'total_mem'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5473/3579954143.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"GPU: {torch.cuda.get_device_name(0)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"VRAM: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ATTENZIONE: Nessuna GPU! Vai su Runtime -> Change runtime type -> GPU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'torch._C._CudaDeviceProperties' object has no attribute 'total_mem'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "2yv0RTfuZJii",
        "outputId": "34a20fa0-d919-4eee-97aa-e8e95712aefe"
      },
      "source": [
        "# === CELLA 2: Upload Dataset ===\n",
        "# Monta Google Drive per accedere ai dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# === MODIFICA QUESTI PATH con la posizione dei tuoi dataset su Drive ===\n",
        "import os, shutil\n",
        "\n",
        "DRIVE_DATASETS = {\n",
        "    \"chest_xray\": \"/content/drive/MyDrive/FL-EHDS-FLICS2026/fl-ehds-framework/data/chest_xray\",\n",
        "    \"Brain_Tumor\": \"/content/drive/MyDrive/FL-EHDS-FLICS2026/fl-ehds-framework/data/Brain_Tumor\",\n",
        "    \"Skin Cancer\": \"/content/drive/MyDrive/FL-EHDS-FLICS2026/fl-ehds-framework/data/Skin Cancer\",\n",
        "}\n",
        "\n",
        "for name, drive_path in DRIVE_DATASETS.items():\n",
        "    local_path = f\"data/{name}\"\n",
        "    if os.path.exists(local_path):\n",
        "        count = sum(1 for r,d,f in os.walk(local_path) for fn in f if fn.lower().endswith(('.jpg','.png','.jpeg')))\n",
        "        print(f\"{name}: gia presente ({count} immagini)\")\n",
        "    elif os.path.exists(drive_path):\n",
        "        print(f\"{name}: copio da Drive...\")\n",
        "        shutil.copytree(drive_path, local_path)\n",
        "        count = sum(1 for r,d,f in os.walk(local_path) for fn in f if fn.lower().endswith(('.jpg','.png','.jpeg')))\n",
        "        print(f\"{name}: OK ({count} immagini)\")\n",
        "    else:\n",
        "        print(f\"{name}: NON TROVATO su Drive! Modifica DRIVE_DATASETS con il path corretto.\")\n",
        "        print(f\"  Path cercato: {drive_path}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "chest_xray: NON TROVATO su Drive! Modifica DRIVE_DATASETS con il path corretto.\n",
            "  Path cercato: /content/drive/MyDrive/FL-EHDS-FLICS2026/fl-ehds-framework/data/chest-xray\n",
            "Brain_Tumor: copio da Drive...\n",
            "Brain_Tumor: OK (7023 immagini)\n",
            "Skin Cancer: copio da Drive...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5473/4186799954.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{name}: copio da Drive...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopytree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{name}: OK ({count} immagini)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m     return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n\u001b[0m\u001b[1;32m    601\u001b[0m                      \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                      \u001b[0mignore_dangling_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_dangling_symlinks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36m_copytree\u001b[0;34m(entries, src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    534\u001b[0m                         \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrcobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdstname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0msrcentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m                 copytree(srcobj, dstname, symlinks, ignore, copy_function,\n\u001b[0m\u001b[1;32m    537\u001b[0m                          ignore_dangling_symlinks, dirs_exist_ok)\n\u001b[1;32m    538\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m     return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n\u001b[0m\u001b[1;32m    601\u001b[0m                      \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                      \u001b[0mignore_dangling_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_dangling_symlinks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36m_copytree\u001b[0;34m(entries, src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    534\u001b[0m                         \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrcobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdstname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0msrcentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m                 copytree(srcobj, dstname, symlinks, ignore, copy_function,\n\u001b[0m\u001b[1;32m    537\u001b[0m                          ignore_dangling_symlinks, dirs_exist_ok)\n\u001b[1;32m    538\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m     return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n\u001b[0m\u001b[1;32m    601\u001b[0m                      \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                      \u001b[0mignore_dangling_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_dangling_symlinks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36m_copytree\u001b[0;34m(entries, src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0;31m# Will raise a SpecialFileError for unsupported file types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m                 \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrcobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdstname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0;31m# catch the Error from the recursive copytree so that we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;31m# continue with other files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CELLA 2 BIS: scarica correttamente e velocemente i db da kaggle ===\n",
        "\n",
        "# Download ALL datasets from Kaggle (fast, single archive each)\n",
        "!pip install -q kagglehub\n",
        "import kagglehub, shutil, os, glob\n",
        "\n",
        "os.environ['KAGGLE_API_TOKEN'] = 'KGAT_edd561c1bc682c9ad06930bacd164431'\n",
        "\n",
        "# 1. Chest X-Ray (~2.3 GB)\n",
        "if not os.path.exists('data/chest_xray/train'):\n",
        "    print('Downloading Chest X-Ray...')\n",
        "    cache_path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
        "    os.makedirs('data/chest_xray', exist_ok=True)\n",
        "    for item in ['train', 'test', 'val']:\n",
        "        src = os.path.join(cache_path, 'chest_xray', item)\n",
        "        if not os.path.exists(src):\n",
        "            src = os.path.join(cache_path, item)\n",
        "        dst = f'data/chest_xray/{item}'\n",
        "        if os.path.exists(src) and not os.path.exists(dst):\n",
        "            shutil.copytree(src, dst)\n",
        "    shutil.rmtree('data/chest_xray/__MACOSX', ignore_errors=True)\n",
        "else:\n",
        "    print('Chest X-Ray: gia presente')\n",
        "\n",
        "# 2. Skin Cancer (~325 MB)\n",
        "if not os.path.exists('data/Skin Cancer'):\n",
        "    print('Downloading Skin Cancer...')\n",
        "    cache_path = kagglehub.dataset_download(\"fanconic/skin-cancer-malignant-vs-benign\")\n",
        "    shutil.copytree(cache_path, 'data/Skin Cancer')\n",
        "else:\n",
        "    print('Skin Cancer: gia presente')\n",
        "\n",
        "# 3. Brain Tumor (~250 MB)\n",
        "if not os.path.exists('data/Brain_Tumor') or len(os.listdir('data/Brain_Tumor')) < 3:\n",
        "    print('Downloading Brain Tumor...')\n",
        "    cache_path = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
        "    os.makedirs('data/Brain_Tumor', exist_ok=True)\n",
        "    for root, dirs, files in os.walk(cache_path):\n",
        "        for d in dirs:\n",
        "            d_lower = d.lower()\n",
        "            if d_lower in ['glioma', 'meningioma', 'pituitary', 'notumor', 'no_tumor', 'healthy']:\n",
        "                target = 'healthy' if d_lower in ['notumor', 'no_tumor'] else d_lower\n",
        "                src = os.path.join(root, d)\n",
        "                dst_dir = f'data/Brain_Tumor/{target}'\n",
        "                if not os.path.exists(dst_dir):\n",
        "                    shutil.copytree(src, dst_dir)\n",
        "                else:\n",
        "                    for f in os.listdir(src):\n",
        "                        src_f, dst_f = os.path.join(src, f), os.path.join(dst_dir, f)\n",
        "                        if os.path.isfile(src_f) and not os.path.exists(dst_f):\n",
        "                            shutil.copy2(src_f, dst_f)\n",
        "else:\n",
        "    print('Brain Tumor: gia presente')\n",
        "\n",
        "# Cleanup + verify\n",
        "import subprocess\n",
        "subprocess.run(['find', 'data/', '-name', '._*', '-delete'], capture_output=True)\n",
        "\n",
        "print('\\n=== Dataset Summary ===')\n",
        "for name, path in [('Chest X-Ray', 'data/chest_xray'), ('Skin Cancer', 'data/Skin Cancer'), ('Brain Tumor', 'data/Brain_Tumor')]:\n",
        "    if os.path.exists(path):\n",
        "        count = sum(1 for _ in glob.iglob(f'{path}/**/*.*', recursive=True) if _.lower().endswith(('.jpg','.jpeg','.png')))\n",
        "        print(f'  {name:15s}: {count:5d} images')\n",
        "    else:\n",
        "        print(f'  {name:15s}: MANCANTE!')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3w18DAFdS4c",
        "outputId": "e303d295-714f-48e0-84e7-5e4753413e20"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Chest X-Ray...\n",
            "Using Colab cache for faster access to the 'chest-xray-pneumonia' dataset.\n",
            "Skin Cancer: gia presente\n",
            "Brain Tumor: gia presente\n",
            "\n",
            "=== Dataset Summary ===\n",
            "  Chest X-Ray    :  5856 images\n",
            "  Skin Cancer    :  5410 images\n",
            "  Brain Tumor    :  7023 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCNrBnk0ZJii",
        "outputId": "9c9d9852-47da-41e7-9f01-c1a96f74bfe9"
      },
      "source": [
        "# === CELLA 3: Pulisci file ._ macOS (evita warning) ===\n",
        "import subprocess\n",
        "result = subprocess.run(['find', 'data/', '-name', '._*', '-delete'], capture_output=True, text=True)\n",
        "print(\"File ._ macOS rimossi (evita warning durante training)\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ._ macOS rimossi (evita warning durante training)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2P2M-ePZJii",
        "outputId": "fd347e2b-f545-4651-d3dc-83a1cae4df92"
      },
      "source": [
        "# === CELLA 4: Script HealthcareCNN ===\n",
        "%%writefile benchmarks/run_imaging_cnn_comparison.py\n",
        "\"\"\"HealthcareCNN (~500K params) comparison on imaging datasets.\"\"\"\n",
        "import sys, json, time, gc, traceback\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np, torch\n",
        "\n",
        "FRAMEWORK_DIR = Path(__file__).parent.parent\n",
        "sys.path.insert(0, str(FRAMEWORK_DIR))\n",
        "from terminal.fl_trainer import ImageFederatedTrainer, _detect_device\n",
        "\n",
        "ALGORITHMS = [\"FedAvg\", \"Ditto\", \"HPFL\"]\n",
        "SEEDS = [42, 123, 456]\n",
        "DATASETS = {\n",
        "    \"chest_xray\": {\"data_dir\": str(FRAMEWORK_DIR / \"data\" / \"chest_xray\"), \"num_classes\": 2},\n",
        "    \"Brain_Tumor\": {\"data_dir\": str(FRAMEWORK_DIR / \"data\" / \"Brain_Tumor\"), \"num_classes\": 4},\n",
        "    \"Skin_Cancer\": {\"data_dir\": str(FRAMEWORK_DIR / \"data\" / \"Skin Cancer\"), \"num_classes\": 2},\n",
        "}\n",
        "CONFIG = dict(\n",
        "    num_clients=5, num_rounds=20, local_epochs=2, batch_size=32,\n",
        "    learning_rate=0.001, model_type=\"cnn\",\n",
        "    is_iid=False, alpha=0.5, freeze_backbone=False, freeze_level=0,\n",
        "    use_fedbn=True, use_class_weights=True, use_amp=True, mu=0.1,\n",
        ")\n",
        "EARLY_STOPPING = dict(enabled=True, patience=4, min_delta=0.003, min_rounds=8, metric=\"accuracy\")\n",
        "\n",
        "OUTPUT = FRAMEWORK_DIR / \"benchmarks\" / \"paper_results_delta\"\n",
        "OUTPUT.mkdir(parents=True, exist_ok=True)\n",
        "CKPT_FILE = OUTPUT / \"checkpoint_imaging_cnn.json\"\n",
        "\n",
        "def load_checkpoint():\n",
        "    if CKPT_FILE.exists():\n",
        "        with open(CKPT_FILE) as f:\n",
        "            return json.load(f)\n",
        "    return {\"completed\": {}, \"meta\": {\"started\": str(datetime.now()), \"model\": \"HealthcareCNN\"}}\n",
        "\n",
        "def save_checkpoint(ckpt):\n",
        "    tmp = CKPT_FILE.with_suffix('.tmp')\n",
        "    with open(tmp, 'w') as f:\n",
        "        json.dump(ckpt, f, indent=2, default=str)\n",
        "    tmp.rename(CKPT_FILE)\n",
        "\n",
        "def main():\n",
        "    device = _detect_device()\n",
        "    ckpt = load_checkpoint()\n",
        "    experiments = [(ds, algo, seed) for ds in DATASETS for algo in ALGORITHMS for seed in SEEDS]\n",
        "    total = len(experiments)\n",
        "    done = len([k for k, v in ckpt[\"completed\"].items() if \"error\" not in v])\n",
        "    print(f\"=== HealthcareCNN Imaging Comparison ===\")\n",
        "    print(f\"Total: {total}, Already done: {done}, Remaining: {total - done}\")\n",
        "    print(f\"Device: {device}\\n\")\n",
        "\n",
        "    for i, (ds, algo, seed) in enumerate(experiments):\n",
        "        key = f\"{ds}_{algo}_s{seed}\"\n",
        "        if key in ckpt[\"completed\"] and \"error\" not in ckpt[\"completed\"][key]:\n",
        "            continue\n",
        "        print(f\"\\n[{done+1}/{total}] {key}\")\n",
        "        t0 = time.time()\n",
        "        try:\n",
        "            ds_info = DATASETS[ds]\n",
        "            cfg = {**CONFIG, \"num_classes\": ds_info[\"num_classes\"]}\n",
        "            if ds == \"Brain_Tumor\":\n",
        "                cfg[\"learning_rate\"] = 0.0005\n",
        "            np.random.seed(seed); torch.manual_seed(seed)\n",
        "            trainer = ImageFederatedTrainer(\n",
        "                data_dir=ds_info[\"data_dir\"], algorithm=algo, seed=seed,\n",
        "                early_stopping_config=EARLY_STOPPING, **cfg\n",
        "            )\n",
        "            result = trainer.train()\n",
        "            elapsed = time.time() - t0\n",
        "            ckpt[\"completed\"][key] = {\n",
        "                \"accuracy\": result.get(\"final_accuracy\", 0),\n",
        "                \"best_accuracy\": result.get(\"best_accuracy\", 0),\n",
        "                \"rounds\": result.get(\"rounds_completed\", 0),\n",
        "                \"time_s\": round(elapsed, 1),\n",
        "                \"model\": \"HealthcareCNN\",\n",
        "                \"algorithm\": algo,\n",
        "                \"dataset\": ds,\n",
        "                \"seed\": seed,\n",
        "            }\n",
        "            done += 1\n",
        "            print(f\"  Done: acc={ckpt['completed'][key]['best_accuracy']:.4f}, {elapsed:.0f}s\")\n",
        "            del trainer; gc.collect(); torch.cuda.empty_cache()\n",
        "        except Exception as e:\n",
        "            ckpt[\"completed\"][key] = {\"error\": str(e), \"traceback\": traceback.format_exc()}\n",
        "            print(f\"  ERROR: {e}\")\n",
        "        save_checkpoint(ckpt)\n",
        "\n",
        "    print(f\"\\n=== COMPLETED: {done}/{total} ===\")\n",
        "    # Summary table\n",
        "    print(f\"\\n{'Dataset':<15} {'Algorithm':<10} {'Acc (mean±std)'}\")\n",
        "    for ds in DATASETS:\n",
        "        for algo in ALGORITHMS:\n",
        "            accs = [ckpt['completed'].get(f'{ds}_{algo}_s{s}', {}).get('best_accuracy', 0) for s in SEEDS]\n",
        "            accs = [a for a in accs if a > 0]\n",
        "            if accs:\n",
        "                print(f\"{ds:<15} {algo:<10} {np.mean(accs)*100:.1f} ± {np.std(accs)*100:.1f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing benchmarks/run_imaging_cnn_comparison.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === sistema dipendenza\n",
        "!pip install -q structlog cryptography grpcio aiohttp pydantic pyyaml\n"
      ],
      "metadata": {
        "id": "RJwaLmjsgP00",
        "outputId": "119f1506-2863-4f19-b3dc-466a54f2056c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/72.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prima cancella il checkpoint con errori\n",
        "!rm -f benchmarks/paper_results_delta/checkpoint_imaging_cnn.json\n"
      ],
      "metadata": {
        "id": "R2nYNI4jg740"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile benchmarks/run_imaging_cnn_comparison.py\n",
        "\"\"\"HealthcareCNN (~500K params) comparison on imaging datasets.\"\"\"\n",
        "import sys, json, time, gc, traceback\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np, torch\n",
        "\n",
        "FRAMEWORK_DIR = Path(__file__).parent.parent\n",
        "sys.path.insert(0, str(FRAMEWORK_DIR))\n",
        "from terminal.fl_trainer import ImageFederatedTrainer, _detect_device\n",
        "\n",
        "ALGORITHMS = [\"FedAvg\", \"Ditto\", \"HPFL\"]\n",
        "SEEDS = [42, 123, 456]\n",
        "DATASETS = {\n",
        "    \"chest_xray\": {\"data_dir\": str(FRAMEWORK_DIR / \"data\" / \"chest_xray\"), \"num_classes\": 2},\n",
        "    \"Brain_Tumor\": {\"data_dir\": str(FRAMEWORK_DIR / \"data\" / \"Brain_Tumor\"), \"num_classes\": 4},\n",
        "    \"Skin_Cancer\": {\"data_dir\": str(FRAMEWORK_DIR / \"data\" / \"Skin Cancer\"), \"num_classes\": 2},\n",
        "}\n",
        "\n",
        "OUTPUT = FRAMEWORK_DIR / \"benchmarks\" / \"paper_results_delta\"\n",
        "OUTPUT.mkdir(parents=True, exist_ok=True)\n",
        "CKPT_FILE = OUTPUT / \"checkpoint_imaging_cnn.json\"\n",
        "\n",
        "def load_checkpoint():\n",
        "    if CKPT_FILE.exists():\n",
        "        with open(CKPT_FILE) as f:\n",
        "            return json.load(f)\n",
        "    return {\"completed\": {}, \"meta\": {\"started\": str(datetime.now()), \"model\": \"HealthcareCNN\"}}\n",
        "\n",
        "def save_checkpoint(ckpt):\n",
        "    tmp = CKPT_FILE.with_suffix('.tmp')\n",
        "    with open(tmp, 'w') as f:\n",
        "        json.dump(ckpt, f, indent=2, default=str)\n",
        "    tmp.rename(CKPT_FILE)\n",
        "\n",
        "def main():\n",
        "    device = _detect_device()\n",
        "    ckpt = load_checkpoint()\n",
        "    experiments = [(ds, algo, seed) for ds in DATASETS for algo in ALGORITHMS for seed in SEEDS]\n",
        "    total = len(experiments)\n",
        "    done = len([k for k, v in ckpt[\"completed\"].items() if \"error\" not in v])\n",
        "    print(f\"=== HealthcareCNN Imaging Comparison ===\")\n",
        "    print(f\"Total: {total}, Already done: {done}, Remaining: {total - done}\")\n",
        "    print(f\"Device: {device}\\n\")\n",
        "\n",
        "    for i, (ds, algo, seed) in enumerate(experiments):\n",
        "        key = f\"{ds}_{algo}_s{seed}\"\n",
        "        if key in ckpt[\"completed\"] and \"error\" not in ckpt[\"completed\"][key]:\n",
        "            continue\n",
        "        print(f\"\\n[{done+1}/{total}] {key}\")\n",
        "        t0 = time.time()\n",
        "        try:\n",
        "            ds_info = DATASETS[ds]\n",
        "            lr = 0.0005 if ds == \"Brain_Tumor\" else 0.001\n",
        "            np.random.seed(seed); torch.manual_seed(seed)\n",
        "            trainer = ImageFederatedTrainer(\n",
        "                data_dir=ds_info[\"data_dir\"],\n",
        "                num_clients=5,\n",
        "                algorithm=algo,\n",
        "                local_epochs=2,\n",
        "                batch_size=32,\n",
        "                learning_rate=lr,\n",
        "                model_type=\"cnn\",\n",
        "                is_iid=False,\n",
        "                alpha=0.5,\n",
        "                freeze_backbone=False,\n",
        "                use_fedbn=True,\n",
        "                use_class_weights=True,\n",
        "                use_amp=True,\n",
        "                mu=0.1,\n",
        "                seed=seed,\n",
        "            )\n",
        "            trainer.num_rounds = 20\n",
        "            result = trainer.train()\n",
        "            elapsed = time.time() - t0\n",
        "            ckpt[\"completed\"][key] = {\n",
        "                \"accuracy\": result.get(\"final_accuracy\", 0),\n",
        "                \"best_accuracy\": result.get(\"best_accuracy\", 0),\n",
        "                \"rounds\": result.get(\"rounds_completed\", 0),\n",
        "                \"time_s\": round(elapsed, 1),\n",
        "                \"model\": \"HealthcareCNN\",\n",
        "                \"algorithm\": algo,\n",
        "                \"dataset\": ds,\n",
        "                \"seed\": seed,\n",
        "            }\n",
        "            done += 1\n",
        "            print(f\"  Done: acc={ckpt['completed'][key]['best_accuracy']:.4f}, {elapsed:.0f}s\")\n",
        "            del trainer; gc.collect(); torch.cuda.empty_cache()\n",
        "        except Exception as e:\n",
        "            ckpt[\"completed\"][key] = {\"error\": str(e), \"traceback\": traceback.format_exc()}\n",
        "            print(f\"  ERROR: {e}\")\n",
        "        save_checkpoint(ckpt)\n",
        "\n",
        "    print(f\"\\n=== COMPLETED: {done}/{total} ===\")\n",
        "    print(f\"\\n{'Dataset':<15} {'Algorithm':<10} {'Acc (mean +/- std)'}\")\n",
        "    print('-' * 45)\n",
        "    for ds in DATASETS:\n",
        "        for algo in ALGORITHMS:\n",
        "            accs = [ckpt['completed'].get(f'{ds}_{algo}_s{s}', {}).get('best_accuracy', 0) for s in SEEDS]\n",
        "            accs = [a for a in accs if a > 0]\n",
        "            if accs:\n",
        "                print(f\"{ds:<15} {algo:<10} {np.mean(accs)*100:.1f} +/- {np.std(accs)*100:.1f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "X1YGQ3DchHVh",
        "outputId": "4b4af803-c104-4c9c-cdb6-736c9901d9cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting benchmarks/run_imaging_cnn_comparison.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmuv4sqGZJij",
        "outputId": "d0d27201-36e4-49fc-fe50-b915fdad7f32"
      },
      "source": [
        "# === CELLA 5: Lancia esperimenti ===\n",
        "!python benchmarks/run_imaging_cnn_comparison.py\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== HealthcareCNN Imaging Comparison ===\n",
            "Total: 27, Already done: 0, Remaining: 27\n",
            "Device: cuda\n",
            "\n",
            "\n",
            "[1/27] chest_xray_FedAvg_s42\n",
            "Loading dataset from: /content/FL-EHDS-FLICS2026/fl-ehds-framework/data/chest_xray\n",
            "Found 2 classes: ['NORMAL', 'PNEUMONIA']\n",
            "  Found 5856 images to load\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMBnZlrTZJij"
      },
      "source": [
        "# === CELLA 6: Scarica risultati ===\n",
        "from google.colab import files\n",
        "files.download('benchmarks/paper_results_delta/checkpoint_imaging_cnn.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDEZzW3WZJij"
      },
      "source": [
        "# === CELLA 7: Salva anche su Drive (backup) ===\n",
        "import shutil\n",
        "shutil.copy(\n",
        "    'benchmarks/paper_results_delta/checkpoint_imaging_cnn.json',\n",
        "    '/content/drive/MyDrive/checkpoint_imaging_cnn.json'\n",
        ")\n",
        "print('Salvato su Google Drive!')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
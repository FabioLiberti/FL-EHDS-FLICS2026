{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FL-EHDS — HealthcareCNN Imaging Comparison\n",
    "\n",
    "Confronto HealthcareCNN (~500K params) vs ResNet-18 (11.2M params) su dataset imaging.\n",
    "\n",
    "- **27 esperimenti**: 3 algos × 3 datasets × 3 seeds\n",
    "- **Tempo stimato**: ~1.5-2.5 ore su GPU T4/A100\n",
    "- **Checkpoint**: salvataggio automatico ogni esperimento\n",
    "\n",
    "**IMPORTANTE**: Seleziona GPU runtime: Runtime → Change runtime type → GPU"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === CELLA 1: Setup ===\n",
    "!git clone https://github.com/FabioLiberti/FL-EHDS-FLICS2026.git\n",
    "%cd FL-EHDS-FLICS2026/fl-ehds-framework\n",
    "!pip install -q opacus>=1.4.0 scikit-learn scipy tqdm rich pydantic pyyaml\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"ATTENZIONE: Nessuna GPU! Vai su Runtime -> Change runtime type -> GPU\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === CELLA 2: Upload Dataset ===\n",
    "# Monta Google Drive per accedere ai dataset\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# === MODIFICA QUESTI PATH con la posizione dei tuoi dataset su Drive ===\n",
    "import os, shutil\n",
    "\n",
    "DRIVE_DATASETS = {\n",
    "    \"chest_xray\": \"/content/drive/MyDrive/chest_xray\",\n",
    "    \"Brain_Tumor\": \"/content/drive/MyDrive/Brain_Tumor\",\n",
    "    \"Skin Cancer\": \"/content/drive/MyDrive/Skin Cancer\",\n",
    "}\n",
    "\n",
    "for name, drive_path in DRIVE_DATASETS.items():\n",
    "    local_path = f\"data/{name}\"\n",
    "    if os.path.exists(local_path):\n",
    "        count = sum(1 for r,d,f in os.walk(local_path) for fn in f if fn.lower().endswith(('.jpg','.png','.jpeg')))\n",
    "        print(f\"{name}: gia presente ({count} immagini)\")\n",
    "    elif os.path.exists(drive_path):\n",
    "        print(f\"{name}: copio da Drive...\")\n",
    "        shutil.copytree(drive_path, local_path)\n",
    "        count = sum(1 for r,d,f in os.walk(local_path) for fn in f if fn.lower().endswith(('.jpg','.png','.jpeg')))\n",
    "        print(f\"{name}: OK ({count} immagini)\")\n",
    "    else:\n",
    "        print(f\"{name}: NON TROVATO su Drive! Modifica DRIVE_DATASETS con il path corretto.\")\n",
    "        print(f\"  Path cercato: {drive_path}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === CELLA 3: Pulisci file ._ macOS (evita warning) ===\n",
    "import subprocess\n",
    "result = subprocess.run(['find', 'data/', '-name', '._*', '-delete'], capture_output=True, text=True)\n",
    "print(\"File ._ macOS rimossi (evita warning durante training)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === CELLA 4: Script HealthcareCNN ===\n",
    "%%writefile benchmarks/run_imaging_cnn_comparison.py\n",
    "\"\"\"HealthcareCNN (~500K params) comparison on imaging datasets.\"\"\"\n",
    "import sys, json, time, gc, traceback\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np, torch\n",
    "\n",
    "FRAMEWORK_DIR = Path(__file__).parent.parent\n",
    "sys.path.insert(0, str(FRAMEWORK_DIR))\n",
    "from terminal.fl_trainer import ImageFederatedTrainer, _detect_device\n",
    "\n",
    "ALGORITHMS = [\"FedAvg\", \"Ditto\", \"HPFL\"]\n",
    "SEEDS = [42, 123, 456]\n",
    "DATASETS = {\n",
    "    \"chest_xray\": {\"data_dir\": str(FRAMEWORK_DIR / \"data\" / \"chest_xray\"), \"num_classes\": 2},\n",
    "    \"Brain_Tumor\": {\"data_dir\": str(FRAMEWORK_DIR / \"data\" / \"Brain_Tumor\"), \"num_classes\": 4},\n",
    "    \"Skin_Cancer\": {\"data_dir\": str(FRAMEWORK_DIR / \"data\" / \"Skin Cancer\"), \"num_classes\": 2},\n",
    "}\n",
    "CONFIG = dict(\n",
    "    num_clients=5, num_rounds=20, local_epochs=2, batch_size=32,\n",
    "    learning_rate=0.001, model_type=\"cnn\",\n",
    "    is_iid=False, alpha=0.5, freeze_backbone=False, freeze_level=0,\n",
    "    use_fedbn=True, use_class_weights=True, use_amp=True, mu=0.1,\n",
    ")\n",
    "EARLY_STOPPING = dict(enabled=True, patience=4, min_delta=0.003, min_rounds=8, metric=\"accuracy\")\n",
    "\n",
    "OUTPUT = FRAMEWORK_DIR / \"benchmarks\" / \"paper_results_delta\"\n",
    "OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "CKPT_FILE = OUTPUT / \"checkpoint_imaging_cnn.json\"\n",
    "\n",
    "def load_checkpoint():\n",
    "    if CKPT_FILE.exists():\n",
    "        with open(CKPT_FILE) as f:\n",
    "            return json.load(f)\n",
    "    return {\"completed\": {}, \"meta\": {\"started\": str(datetime.now()), \"model\": \"HealthcareCNN\"}}\n",
    "\n",
    "def save_checkpoint(ckpt):\n",
    "    tmp = CKPT_FILE.with_suffix('.tmp')\n",
    "    with open(tmp, 'w') as f:\n",
    "        json.dump(ckpt, f, indent=2, default=str)\n",
    "    tmp.rename(CKPT_FILE)\n",
    "\n",
    "def main():\n",
    "    device = _detect_device()\n",
    "    ckpt = load_checkpoint()\n",
    "    experiments = [(ds, algo, seed) for ds in DATASETS for algo in ALGORITHMS for seed in SEEDS]\n",
    "    total = len(experiments)\n",
    "    done = len([k for k, v in ckpt[\"completed\"].items() if \"error\" not in v])\n",
    "    print(f\"=== HealthcareCNN Imaging Comparison ===\")\n",
    "    print(f\"Total: {total}, Already done: {done}, Remaining: {total - done}\")\n",
    "    print(f\"Device: {device}\\n\")\n",
    "\n",
    "    for i, (ds, algo, seed) in enumerate(experiments):\n",
    "        key = f\"{ds}_{algo}_s{seed}\"\n",
    "        if key in ckpt[\"completed\"] and \"error\" not in ckpt[\"completed\"][key]:\n",
    "            continue\n",
    "        print(f\"\\n[{done+1}/{total}] {key}\")\n",
    "        t0 = time.time()\n",
    "        try:\n",
    "            ds_info = DATASETS[ds]\n",
    "            cfg = {**CONFIG, \"num_classes\": ds_info[\"num_classes\"]}\n",
    "            if ds == \"Brain_Tumor\":\n",
    "                cfg[\"learning_rate\"] = 0.0005\n",
    "            np.random.seed(seed); torch.manual_seed(seed)\n",
    "            trainer = ImageFederatedTrainer(\n",
    "                data_dir=ds_info[\"data_dir\"], algorithm=algo, seed=seed,\n",
    "                early_stopping_config=EARLY_STOPPING, **cfg\n",
    "            )\n",
    "            result = trainer.train()\n",
    "            elapsed = time.time() - t0\n",
    "            ckpt[\"completed\"][key] = {\n",
    "                \"accuracy\": result.get(\"final_accuracy\", 0),\n",
    "                \"best_accuracy\": result.get(\"best_accuracy\", 0),\n",
    "                \"rounds\": result.get(\"rounds_completed\", 0),\n",
    "                \"time_s\": round(elapsed, 1),\n",
    "                \"model\": \"HealthcareCNN\",\n",
    "                \"algorithm\": algo,\n",
    "                \"dataset\": ds,\n",
    "                \"seed\": seed,\n",
    "            }\n",
    "            done += 1\n",
    "            print(f\"  Done: acc={ckpt['completed'][key]['best_accuracy']:.4f}, {elapsed:.0f}s\")\n",
    "            del trainer; gc.collect(); torch.cuda.empty_cache()\n",
    "        except Exception as e:\n",
    "            ckpt[\"completed\"][key] = {\"error\": str(e), \"traceback\": traceback.format_exc()}\n",
    "            print(f\"  ERROR: {e}\")\n",
    "        save_checkpoint(ckpt)\n",
    "\n",
    "    print(f\"\\n=== COMPLETED: {done}/{total} ===\")\n",
    "    # Summary table\n",
    "    print(f\"\\n{'Dataset':<15} {'Algorithm':<10} {'Acc (mean±std)'}\")\n",
    "    for ds in DATASETS:\n",
    "        for algo in ALGORITHMS:\n",
    "            accs = [ckpt['completed'].get(f'{ds}_{algo}_s{s}', {}).get('best_accuracy', 0) for s in SEEDS]\n",
    "            accs = [a for a in accs if a > 0]\n",
    "            if accs:\n",
    "                print(f\"{ds:<15} {algo:<10} {np.mean(accs)*100:.1f} ± {np.std(accs)*100:.1f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === CELLA 5: Lancia esperimenti ===\n",
    "!python benchmarks/run_imaging_cnn_comparison.py"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === CELLA 6: Scarica risultati ===\n",
    "from google.colab import files\n",
    "files.download('benchmarks/paper_results_delta/checkpoint_imaging_cnn.json')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# === CELLA 7: Salva anche su Drive (backup) ===\n",
    "import shutil\n",
    "shutil.copy(\n",
    "    'benchmarks/paper_results_delta/checkpoint_imaging_cnn.json',\n",
    "    '/content/drive/MyDrive/checkpoint_imaging_cnn.json'\n",
    ")\n",
    "print('Salvato su Google Drive!')"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FL-EHDS — HealthcareCNN Imaging Comparison\n",
    "\n",
    "Confronto HealthcareCNN (~500K params) vs ResNet-18 (11.2M params) su dataset imaging.\n",
    "\n",
    "- **27 esperimenti**: 3 algos (FedAvg, Ditto, HPFL) × 3 datasets × 3 seeds\n",
    "- **Tempo stimato**: ~1.5-2.5 ore su GPU T4/A100\n",
    "- **Checkpoint**: salvataggio automatico su Google Drive ogni esperimento\n",
    "\n",
    "**IMPORTANTE**: Runtime → Change runtime type → **GPU (T4)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Mount Google Drive for persistent checkpoint storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "DRIVE_OUTPUT = '/content/drive/MyDrive/FL-EHDS-FLICS2026/colab_results'\n",
    "os.makedirs(DRIVE_OUTPUT, exist_ok=True)\n",
    "print(f'Drive output: {DRIVE_OUTPUT}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    mem = getattr(props, 'total_memory', None) or getattr(props, 'total_mem', 0)\n",
    "    print(f'Memory: {mem / 1e9:.1f} GB')\n",
    "else:\n",
    "    print('ATTENZIONE: Nessuna GPU! Vai su Runtime -> Change runtime type -> GPU')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/FabioLiberti/FL-EHDS-FLICS2026.git /content/FL-EHDS-FLICS2026\n",
    "%cd /content/FL-EHDS-FLICS2026/fl-ehds-framework\n",
    "!pip install -q opacus>=1.4.0 scikit-learn scipy tqdm rich pydantic pyyaml"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Datasets (da Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Setup Kaggle API\n",
    "!pip install -q kagglehub\n",
    "\n",
    "import os\n",
    "os.environ['KAGGLE_API_TOKEN'] = 'KGAT_edd561c1bc682c9ad06930bacd164431'\n",
    "\n",
    "import kagglehub\n",
    "print(f'kagglehub version: {kagglehub.__version__}')\n",
    "print('Kaggle auth ready')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%%time\n",
    "# Download Chest X-Ray Pneumonia (~2.3 GB)\n",
    "import kagglehub, shutil, os\n",
    "\n",
    "cache_path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "print(f'Downloaded to cache: {cache_path}')\n",
    "\n",
    "os.makedirs('data/chest_xray', exist_ok=True)\n",
    "for item in ['train', 'test', 'val']:\n",
    "    src = os.path.join(cache_path, 'chest_xray', item)\n",
    "    if not os.path.exists(src):\n",
    "        src = os.path.join(cache_path, item)\n",
    "    dst = f'data/chest_xray/{item}'\n",
    "    if os.path.exists(src) and not os.path.exists(dst):\n",
    "        shutil.copytree(src, dst)\n",
    "        print(f'  Copied {item}')\n",
    "\n",
    "shutil.rmtree('data/chest_xray/__MACOSX', ignore_errors=True)\n",
    "print('Chest X-Ray ready:')\n",
    "!find data/chest_xray -name '*.jpeg' -o -name '*.jpg' -o -name '*.png' | wc -l"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%%time\n",
    "# Download Skin Cancer (~325 MB)\n",
    "cache_path = kagglehub.dataset_download(\"fanconic/skin-cancer-malignant-vs-benign\")\n",
    "print(f'Downloaded to cache: {cache_path}')\n",
    "\n",
    "dst = 'data/Skin Cancer'\n",
    "if not os.path.exists(dst):\n",
    "    shutil.copytree(cache_path, dst)\n",
    "\n",
    "print('Skin Cancer ready:')\n",
    "!find \"data/Skin Cancer\" -name '*.jpg' -o -name '*.jpeg' -o -name '*.png' | wc -l"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%%time\n",
    "# Download Brain Tumor (~250 MB)\n",
    "import glob\n",
    "\n",
    "cache_path = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
    "print(f'Downloaded to cache: {cache_path}')\n",
    "\n",
    "os.makedirs('data/Brain_Tumor', exist_ok=True)\n",
    "for root, dirs, files in os.walk(cache_path):\n",
    "    for d in dirs:\n",
    "        d_lower = d.lower()\n",
    "        if d_lower in ['glioma', 'meningioma', 'pituitary', 'notumor', 'no_tumor', 'healthy']:\n",
    "            target = 'healthy' if d_lower in ['notumor', 'no_tumor'] else d_lower\n",
    "            src = os.path.join(root, d)\n",
    "            dst_dir = f'data/Brain_Tumor/{target}'\n",
    "            if not os.path.exists(dst_dir):\n",
    "                shutil.copytree(src, dst_dir)\n",
    "            else:\n",
    "                for f in os.listdir(src):\n",
    "                    src_f = os.path.join(src, f)\n",
    "                    dst_f = os.path.join(dst_dir, f)\n",
    "                    if os.path.isfile(src_f) and not os.path.exists(dst_f):\n",
    "                        shutil.copy2(src_f, dst_f)\n",
    "\n",
    "print('Brain Tumor ready:')\n",
    "!find data/Brain_Tumor -name '*.jpg' -o -name '*.jpeg' -o -name '*.png' | wc -l\n",
    "!ls data/Brain_Tumor/"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Verify all datasets + remove macOS ._ files\n",
    "import subprocess\n",
    "subprocess.run(['find', 'data/', '-name', '._*', '-delete'], capture_output=True)\n",
    "\n",
    "print('=== Dataset Summary ===')\n",
    "for ds_name, ds_path in [('Chest X-Ray', 'data/chest_xray'),\n",
    "                          ('Skin Cancer', 'data/Skin Cancer'),\n",
    "                          ('Brain Tumor', 'data/Brain_Tumor')]:\n",
    "    count = sum(1 for _ in glob.iglob(f'{ds_path}/**/*.*', recursive=True)\n",
    "                if _.lower().endswith(('.jpg', '.jpeg', '.png')))\n",
    "    subdirs = [d for d in os.listdir(ds_path) if os.path.isdir(os.path.join(ds_path, d))]\n",
    "    print(f'  {ds_name:15s}: {count:5d} images, classes: {subdirs}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run HealthcareCNN Experiments\n",
    "\n",
    "27 esperimenti con checkpoint su Google Drive.\n",
    "Se la sessione si disconnette, ri-esegui questa cella — riprende automaticamente."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%%time\n",
    "import sys, json, time, gc, traceback, shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np, torch\n",
    "\n",
    "FRAMEWORK_DIR = Path('/content/FL-EHDS-FLICS2026/fl-ehds-framework')\n",
    "sys.path.insert(0, str(FRAMEWORK_DIR))\n",
    "from terminal.fl_trainer import ImageFederatedTrainer, _detect_device\n",
    "\n",
    "ALGORITHMS = [\"FedAvg\", \"Ditto\", \"HPFL\"]\n",
    "SEEDS = [42, 123, 456]\n",
    "DATASETS = {\n",
    "    \"chest_xray\": {\"data_dir\": str(FRAMEWORK_DIR / \"data\" / \"chest_xray\"), \"num_classes\": 2},\n",
    "    \"Brain_Tumor\": {\"data_dir\": str(FRAMEWORK_DIR / \"data\" / \"Brain_Tumor\"), \"num_classes\": 4},\n",
    "    \"Skin_Cancer\": {\"data_dir\": str(FRAMEWORK_DIR / \"data\" / \"Skin Cancer\"), \"num_classes\": 2},\n",
    "}\n",
    "CONFIG = dict(\n",
    "    num_clients=5, num_rounds=20, local_epochs=2, batch_size=32,\n",
    "    learning_rate=0.001, model_type=\"cnn\",\n",
    "    is_iid=False, alpha=0.5, freeze_backbone=False, freeze_level=0,\n",
    "    use_fedbn=True, use_class_weights=True, use_amp=True, mu=0.1,\n",
    ")\n",
    "EARLY_STOPPING = dict(enabled=True, patience=4, min_delta=0.003, min_rounds=8, metric=\"accuracy\")\n",
    "\n",
    "# Checkpoint su Google Drive (persiste tra sessioni)\n",
    "DRIVE_OUTPUT = Path('/content/drive/MyDrive/FL-EHDS-FLICS2026/colab_results')\n",
    "DRIVE_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "CKPT_FILE = DRIVE_OUTPUT / 'checkpoint_imaging_cnn.json'\n",
    "\n",
    "def load_checkpoint():\n",
    "    if CKPT_FILE.exists():\n",
    "        with open(CKPT_FILE) as f:\n",
    "            return json.load(f)\n",
    "    return {\"completed\": {}, \"meta\": {\"started\": str(datetime.now()), \"model\": \"HealthcareCNN\"}}\n",
    "\n",
    "def save_checkpoint(ckpt):\n",
    "    tmp = CKPT_FILE.with_suffix('.tmp')\n",
    "    with open(tmp, 'w') as f:\n",
    "        json.dump(ckpt, f, indent=2, default=str)\n",
    "    tmp.rename(CKPT_FILE)\n",
    "\n",
    "device = _detect_device()\n",
    "ckpt = load_checkpoint()\n",
    "experiments = [(ds, algo, seed) for ds in DATASETS for algo in ALGORITHMS for seed in SEEDS]\n",
    "total = len(experiments)\n",
    "done = len([k for k, v in ckpt[\"completed\"].items() if \"error\" not in v])\n",
    "print(f\"=== HealthcareCNN Imaging Comparison ===\")\n",
    "print(f\"Total: {total}, Already done: {done}, Remaining: {total - done}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Checkpoint: {CKPT_FILE}\\n\")\n",
    "\n",
    "for i, (ds, algo, seed) in enumerate(experiments):\n",
    "    key = f\"{ds}_{algo}_s{seed}\"\n",
    "    if key in ckpt[\"completed\"] and \"error\" not in ckpt[\"completed\"][key]:\n",
    "        continue\n",
    "    print(f\"\\n[{done+1}/{total}] {key}\")\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        ds_info = DATASETS[ds]\n",
    "        cfg = {**CONFIG, \"num_classes\": ds_info[\"num_classes\"]}\n",
    "        if ds == \"Brain_Tumor\":\n",
    "            cfg[\"learning_rate\"] = 0.0005\n",
    "        np.random.seed(seed); torch.manual_seed(seed)\n",
    "        trainer = ImageFederatedTrainer(\n",
    "            data_dir=ds_info[\"data_dir\"], algorithm=algo, seed=seed,\n",
    "            early_stopping_config=EARLY_STOPPING, **cfg\n",
    "        )\n",
    "        result = trainer.train()\n",
    "        elapsed = time.time() - t0\n",
    "        ckpt[\"completed\"][key] = {\n",
    "            \"accuracy\": result.get(\"final_accuracy\", 0),\n",
    "            \"best_accuracy\": result.get(\"best_accuracy\", 0),\n",
    "            \"rounds\": result.get(\"rounds_completed\", 0),\n",
    "            \"time_s\": round(elapsed, 1),\n",
    "            \"model\": \"HealthcareCNN\",\n",
    "            \"algorithm\": algo,\n",
    "            \"dataset\": ds,\n",
    "            \"seed\": seed,\n",
    "        }\n",
    "        done += 1\n",
    "        print(f\"  Done: acc={ckpt['completed'][key]['best_accuracy']:.4f}, {elapsed:.0f}s\")\n",
    "        del trainer; gc.collect(); torch.cuda.empty_cache()\n",
    "    except Exception as e:\n",
    "        ckpt[\"completed\"][key] = {\"error\": str(e), \"traceback\": traceback.format_exc()}\n",
    "        print(f\"  ERROR: {e}\")\n",
    "    save_checkpoint(ckpt)\n",
    "\n",
    "print(f\"\\n=== COMPLETED: {done}/{total} ===\")\n",
    "print(f\"\\n{'Dataset':<15} {'Algorithm':<10} {'Acc (mean +/- std)'}\")\n",
    "print('-' * 45)\n",
    "for ds in DATASETS:\n",
    "    for algo in ALGORITHMS:\n",
    "        accs = [ckpt['completed'].get(f'{ds}_{algo}_s{s}', {}).get('best_accuracy', 0) for s in SEEDS]\n",
    "        accs = [a for a in accs if a > 0]\n",
    "        if accs:\n",
    "            print(f\"{ds:<15} {algo:<10} {np.mean(accs)*100:.1f} +/- {np.std(accs)*100:.1f}%\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Download checkpoint (gia salvato su Drive, ma anche scaricabile)\n",
    "from google.colab import files\n",
    "ckpt_path = '/content/drive/MyDrive/FL-EHDS-FLICS2026/colab_results/checkpoint_imaging_cnn.json'\n",
    "if os.path.exists(ckpt_path):\n",
    "    files.download(ckpt_path)\n",
    "    print('Downloaded!')\n",
    "else:\n",
    "    print('No checkpoint found.')"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
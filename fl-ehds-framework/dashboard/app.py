#!/usr/bin/env python3
"""
FL-EHDS Interactive Dashboard

A comprehensive Streamlit dashboard for:
1. Configuring FL experiments (hospitals, rounds, algorithms, privacy)
2. Running federated learning with real-time visualization
3. Analyzing heterogeneity across hospitals
4. Simulating opt-out impact (EHDS Article 71)
5. Comparing gradient compression techniques
6. Viewing all generated experimental results

Author: Fabio Liberti
Usage: streamlit run app.py
"""

import streamlit as st
import numpy as np
import pandas as pd
import json
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import io
import base64

# Page config
st.set_page_config(
    page_title="FL-EHDS Dashboard",
    page_icon="üè•",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 1rem;
        text-align: center;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 24px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        padding-left: 20px;
        padding-right: 20px;
    }
</style>
""", unsafe_allow_html=True)


class FLSimulator:
    """Federated Learning Simulator for the dashboard."""

    def __init__(self, config: Dict):
        self.config = config
        np.random.seed(config.get('random_seed', 42))

        self.num_hospitals = config['num_hospitals']
        self.hospital_names = [
            "IT-Roma", "DE-Berlin", "FR-Paris", "ES-Madrid", "NL-Amsterdam",
            "BE-Brussels", "AT-Vienna", "PT-Lisbon", "GR-Athens", "PL-Warsaw"
        ][:self.num_hospitals]

        self.colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6',
                      '#1abc9c', '#e67e22', '#95a5a6', '#34495e', '#d35400'][:self.num_hospitals]

        self._generate_data()
        self._init_model()

    def _generate_data(self):
        """Generate synthetic healthcare data for each hospital."""
        self.hospital_data = {}

        # Different parameters per hospital (non-IID)
        base_params = [
            {"samples": 400, "age": 48, "pos_rate": 0.38},
            {"samples": 520, "age": 54, "pos_rate": 0.44},
            {"samples": 340, "age": 51, "pos_rate": 0.41},
            {"samples": 480, "age": 59, "pos_rate": 0.56},
            {"samples": 390, "age": 62, "pos_rate": 0.63},
            {"samples": 420, "age": 50, "pos_rate": 0.40},
            {"samples": 380, "age": 56, "pos_rate": 0.48},
            {"samples": 450, "age": 53, "pos_rate": 0.45},
            {"samples": 360, "age": 57, "pos_rate": 0.52},
            {"samples": 410, "age": 55, "pos_rate": 0.47},
        ][:self.num_hospitals]

        # Adjust for non-IID degree
        noniid_degree = self.config.get('noniid_degree', 0.5)

        for name, params in zip(self.hospital_names, base_params):
            n = params["samples"]

            # Generate features
            age_shift = (params["age"] - 55) * noniid_degree
            age = np.random.normal(55 + age_shift, 12, n)
            age = np.clip(age, 18, 95)

            bmi = np.random.normal(26, 4.5, n)
            systolic = np.random.normal(125, 18, n)
            glucose = np.random.normal(100, 22, n)
            cholesterol = np.random.normal(200, 35, n)

            X = np.column_stack([age, bmi, systolic, glucose, cholesterol])
            X_norm = (X - X.mean(axis=0)) / (X.std(axis=0) + 1e-8)

            # Generate labels with hospital-specific rates
            base_rate = 0.5 + (params["pos_rate"] - 0.5) * noniid_degree
            risk = 0.5 * X_norm[:, 0] + 0.3 * X_norm[:, 1] + 0.2 * X_norm[:, 2]
            prob = 1 / (1 + np.exp(-risk))
            y = (np.random.random(n) < prob).astype(int)

            X_bias = np.hstack([X_norm, np.ones((n, 1))])

            self.hospital_data[name] = {
                "X": X_bias,
                "y": y,
                "n_samples": n,
                "demographics": {
                    "mean_age": float(np.mean(age)),
                    "pos_rate": float(np.mean(y))
                }
            }

    def _init_model(self):
        """Initialize model weights."""
        self.weights = np.zeros(6)  # 5 features + bias
        self.privacy_spent = 0.0
        self.total_bytes = 0

    def train_round(self, round_num: int) -> Dict:
        """Execute one FL training round."""
        config = self.config
        lr = config.get('learning_rate', 0.1)
        local_epochs = config.get('local_epochs', 3)
        participation_rate = config.get('participation_rate', 0.85)
        use_dp = config.get('use_dp', True)
        epsilon = config.get('epsilon', 10.0)
        algorithm = config.get('algorithm', 'FedAvg')
        mu = config.get('fedprox_mu', 0.1)

        # Select participating clients
        participating = []
        for name in self.hospital_names:
            if np.random.random() < participation_rate:
                participating.append(name)
        if not participating:
            participating = [self.hospital_names[0]]

        gradients = []
        sample_counts = []
        client_metrics = {}

        for name in self.hospital_names:
            data = self.hospital_data[name]

            if name in participating:
                local_weights = self.weights.copy()

                for _ in range(local_epochs):
                    batch_size = min(32, data["n_samples"])
                    indices = np.random.choice(data["n_samples"], batch_size, replace=False)
                    X_batch = data["X"][indices]
                    y_batch = data["y"][indices]

                    logits = X_batch @ local_weights
                    probs = 1 / (1 + np.exp(-np.clip(logits, -500, 500)))
                    grad = X_batch.T @ (probs - y_batch) / batch_size

                    # FedProx proximal term
                    if algorithm == 'FedProx':
                        grad += mu * (local_weights - self.weights)

                    local_weights -= lr * grad

                gradient = local_weights - self.weights

                # Gradient clipping
                norm = np.linalg.norm(gradient)
                if norm > 1.0:
                    gradient = gradient / norm

                gradients.append(gradient)
                sample_counts.append(data["n_samples"])

            # Evaluate
            logits = data["X"] @ self.weights
            probs = 1 / (1 + np.exp(-np.clip(logits, -500, 500)))
            preds = (probs > 0.5).astype(int)
            accuracy = float(np.mean(preds == data["y"]))

            client_metrics[name] = {
                "accuracy": accuracy,
                "samples": data["n_samples"],
                "participating": name in participating
            }

        # Aggregate
        if gradients:
            total_samples = sum(sample_counts)
            weighted_grad = sum(
                g * (n / total_samples) for g, n in zip(gradients, sample_counts)
            )

            # Add DP noise
            if use_dp:
                noise_scale = 1.0 / epsilon
                noise = np.random.normal(0, noise_scale * 0.01, weighted_grad.shape)
                weighted_grad += noise
                self.privacy_spent += epsilon / config.get('num_rounds', 50)

            self.weights += weighted_grad

        # Communication cost
        self.total_bytes += len(participating) * 6 * 4 * 2

        # Global metrics
        all_preds, all_labels = [], []
        for data in self.hospital_data.values():
            logits = data["X"] @ self.weights
            probs = 1 / (1 + np.exp(-np.clip(logits, -500, 500)))
            preds = (probs > 0.5).astype(int)
            all_preds.extend(preds)
            all_labels.extend(data["y"])

        global_accuracy = float(np.mean(np.array(all_preds) == np.array(all_labels)))

        return {
            "round": round_num,
            "global_accuracy": global_accuracy,
            "client_metrics": client_metrics,
            "participating": participating,
            "privacy_spent": self.privacy_spent,
            "communication_kb": self.total_bytes / 1024
        }


def create_config_panel() -> Dict:
    """Create the configuration panel in the sidebar."""
    st.sidebar.markdown("## ‚öôÔ∏è FL Configuration")

    with st.sidebar.expander("üè• Hospitals", expanded=True):
        num_hospitals = st.slider("Number of Hospitals", 2, 10, 5)
        participation_rate = st.slider("Participation Rate", 0.5, 1.0, 0.85, 0.05)

    with st.sidebar.expander("üîÑ Training", expanded=True):
        num_rounds = st.slider("Training Rounds", 10, 200, 50)
        local_epochs = st.slider("Local Epochs", 1, 10, 3)
        learning_rate = st.select_slider(
            "Learning Rate",
            options=[0.001, 0.01, 0.05, 0.1, 0.2, 0.5],
            value=0.1
        )
        batch_size = st.select_slider(
            "Batch Size",
            options=[8, 16, 32, 64, 128],
            value=32
        )

    with st.sidebar.expander("üßÆ Algorithm", expanded=True):
        algorithm = st.radio("FL Algorithm", ["FedAvg", "FedProx"])
        fedprox_mu = 0.0
        if algorithm == "FedProx":
            fedprox_mu = st.slider("FedProx Œº", 0.01, 1.0, 0.1, 0.01)

    with st.sidebar.expander("üîí Privacy (DP)", expanded=True):
        use_dp = st.checkbox("Enable Differential Privacy", value=True)
        epsilon = st.slider("Privacy Budget (Œµ)", 1.0, 50.0, 10.0, 1.0,
                           disabled=not use_dp)
        clip_norm = st.slider("Gradient Clip Norm", 0.1, 5.0, 1.0, 0.1)

    with st.sidebar.expander("üìä Data Heterogeneity", expanded=False):
        noniid_degree = st.slider("Non-IID Degree", 0.0, 1.0, 0.5, 0.1,
                                  help="0 = IID, 1 = Highly Non-IID")

    with st.sidebar.expander("üé≤ Reproducibility", expanded=False):
        random_seed = st.number_input("Random Seed", 0, 9999, 42)

    return {
        "num_hospitals": num_hospitals,
        "participation_rate": participation_rate,
        "num_rounds": num_rounds,
        "local_epochs": local_epochs,
        "learning_rate": learning_rate,
        "batch_size": batch_size,
        "algorithm": algorithm,
        "fedprox_mu": fedprox_mu,
        "use_dp": use_dp,
        "epsilon": epsilon,
        "clip_norm": clip_norm,
        "noniid_degree": noniid_degree,
        "random_seed": random_seed
    }


def render_training_tab(config: Dict):
    """Render the training visualization tab."""
    st.markdown("### üöÄ Federated Learning Training")

    col1, col2, col3 = st.columns([1, 2, 1])

    with col1:
        st.markdown("#### Configuration Summary")
        st.json({
            "Hospitals": config['num_hospitals'],
            "Rounds": config['num_rounds'],
            "Algorithm": config['algorithm'],
            "DP Enabled": config['use_dp'],
            "Non-IID": f"{config['noniid_degree']:.1f}"
        })

    with col2:
        if st.button("‚ñ∂Ô∏è Start Training", type="primary", use_container_width=True):
            run_training(config)

    with col3:
        st.markdown("#### Expected Results")
        st.metric("Est. Final Accuracy", "55-60%")
        st.metric("Privacy Cost", f"Œµ ‚â§ {config['epsilon']:.1f}")


def run_training(config: Dict):
    """Run FL training with live visualization."""
    simulator = FLSimulator(config)

    # Create placeholders
    progress_bar = st.progress(0)
    status_text = st.empty()

    col1, col2 = st.columns(2)

    with col1:
        accuracy_chart = st.empty()
        metrics_table = st.empty()

    with col2:
        participation_chart = st.empty()
        privacy_chart = st.empty()

    # Training loop
    history = []
    accuracies = []
    participation_matrix = []
    privacy_history = []

    for round_num in range(1, config['num_rounds'] + 1):
        result = simulator.train_round(round_num)
        history.append(result)
        accuracies.append(result['global_accuracy'])
        participation_matrix.append([
            1 if name in result['participating'] else 0
            for name in simulator.hospital_names
        ])
        privacy_history.append(result['privacy_spent'])

        # Update progress
        progress = round_num / config['num_rounds']
        progress_bar.progress(progress)
        status_text.text(f"Round {round_num}/{config['num_rounds']} - "
                        f"Accuracy: {result['global_accuracy']:.2%}")

        # Update accuracy chart
        if round_num % 5 == 0 or round_num == config['num_rounds']:
            fig1, ax1 = plt.subplots(figsize=(8, 4))
            ax1.plot(range(1, len(accuracies) + 1), accuracies, 'b-', linewidth=2)
            ax1.set_xlabel("Round")
            ax1.set_ylabel("Global Accuracy")
            ax1.set_title("Training Convergence")
            ax1.grid(True, alpha=0.3)
            ax1.set_ylim(0.4, 0.7)
            accuracy_chart.pyplot(fig1)
            plt.close(fig1)

            # Update participation heatmap
            fig2, ax2 = plt.subplots(figsize=(8, 3))
            matrix = np.array(participation_matrix).T
            cmap = LinearSegmentedColormap.from_list("", ["#ffcccc", "#28a745"])
            ax2.imshow(matrix, cmap=cmap, aspect='auto')
            ax2.set_yticks(range(len(simulator.hospital_names)))
            ax2.set_yticklabels(simulator.hospital_names)
            ax2.set_xlabel("Round")
            ax2.set_title("Client Participation")
            participation_chart.pyplot(fig2)
            plt.close(fig2)

        # Small delay for visualization
        time.sleep(0.05)

    # Final metrics
    status_text.success(f"‚úÖ Training Complete! Final Accuracy: {accuracies[-1]:.2%}")

    # Show final metrics table
    final_metrics = pd.DataFrame([
        {
            "Hospital": name,
            "Accuracy": f"{result['client_metrics'][name]['accuracy']:.2%}",
            "Samples": result['client_metrics'][name]['samples'],
            "Status": "‚úì" if result['client_metrics'][name]['participating'] else "‚óã"
        }
        for name in simulator.hospital_names
    ])
    metrics_table.dataframe(final_metrics, use_container_width=True)

    # Privacy chart
    fig3, ax3 = plt.subplots(figsize=(8, 3))
    ax3.plot(range(1, len(privacy_history) + 1), privacy_history, 'r-', linewidth=2)
    ax3.axhline(y=config['epsilon'], color='orange', linestyle='--', label=f'Budget Œµ={config["epsilon"]}')
    ax3.set_xlabel("Round")
    ax3.set_ylabel("Œµ spent")
    ax3.set_title("Privacy Budget Consumption")
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    privacy_chart.pyplot(fig3)
    plt.close(fig3)


def render_heterogeneity_tab(config: Dict):
    """Render heterogeneity analysis tab."""
    st.markdown("### üìä Statistical Heterogeneity Analysis")

    simulator = FLSimulator(config)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#### Hospital Demographics")

        demo_data = []
        for name in simulator.hospital_names:
            data = simulator.hospital_data[name]
            demo_data.append({
                "Hospital": name,
                "Samples": data["n_samples"],
                "Mean Age": f"{data['demographics']['mean_age']:.1f}",
                "Pos Rate": f"{data['demographics']['pos_rate']:.1%}"
            })

        df = pd.DataFrame(demo_data)
        st.dataframe(df, use_container_width=True)

        # Label distribution chart
        fig, ax = plt.subplots(figsize=(10, 5))
        pos_rates = [simulator.hospital_data[name]['demographics']['pos_rate']
                    for name in simulator.hospital_names]
        bars = ax.bar(simulator.hospital_names, pos_rates, color=simulator.colors)
        ax.axhline(y=np.mean(pos_rates), color='red', linestyle='--', label='Global Mean')
        ax.set_ylabel("Positive Rate")
        ax.set_title("Label Distribution (Non-IID)")
        ax.legend()
        ax.tick_params(axis='x', rotation=45)
        st.pyplot(fig)
        plt.close(fig)

    with col2:
        st.markdown("#### Non-IID Metrics")

        # Compute KL divergence
        global_pos = np.mean([d['demographics']['pos_rate'] for d in simulator.hospital_data.values()])
        kl_divs = []
        for name in simulator.hospital_names:
            local_pos = simulator.hospital_data[name]['demographics']['pos_rate']
            eps = 1e-10
            kl = local_pos * np.log((local_pos + eps) / (global_pos + eps)) + \
                 (1 - local_pos) * np.log((1 - local_pos + eps) / (1 - global_pos + eps))
            kl_divs.append(abs(kl))

        fig2, ax2 = plt.subplots(figsize=(10, 5))
        bars = ax2.bar(simulator.hospital_names, kl_divs, color=simulator.colors)
        ax2.set_ylabel("KL Divergence")
        ax2.set_title("Divergence from Global Distribution")
        ax2.tick_params(axis='x', rotation=45)
        st.pyplot(fig2)
        plt.close(fig2)

        # Summary metrics
        st.metric("Max KL Divergence", f"{max(kl_divs):.4f}")
        st.metric("Mean KL Divergence", f"{np.mean(kl_divs):.4f}")
        st.metric("Non-IID Score", f"{config['noniid_degree']:.1f}")


def render_optout_tab(config: Dict):
    """Render opt-out impact simulation tab."""
    st.markdown("### üö´ EHDS Article 71 Opt-Out Impact Simulation")

    col1, col2 = st.columns([1, 2])

    with col1:
        st.markdown("#### Opt-Out Configuration")
        opt_out_rates = st.multiselect(
            "Test Opt-Out Rates",
            options=[0, 5, 10, 15, 20, 25, 30, 40, 50, 60, 70],
            default=[0, 10, 20, 30, 50]
        )
        opt_out_rates = [r / 100 for r in sorted(opt_out_rates)]

        if st.button("üîç Run Simulation", type="primary"):
            run_optout_simulation(config, opt_out_rates)

    with col2:
        st.markdown("#### About Opt-Out Rights")
        st.info("""
        **EHDS Article 71** grants EU citizens the right to opt-out of secondary use
        of their electronic health data. This simulation shows how different opt-out
        rates affect FL model performance.

        **Key Questions:**
        - At what opt-out rate does the model become non-viable?
        - How should HDABs plan for citizen engagement?
        """)


def run_optout_simulation(config: Dict, opt_out_rates: List[float]):
    """Run opt-out impact simulation."""
    progress = st.progress(0)
    results = []

    # Baseline
    baseline_config = config.copy()
    baseline_config['num_rounds'] = 30
    simulator = FLSimulator(baseline_config)

    for _ in range(30):
        simulator.train_round(_ + 1)

    baseline_acc = sum([
        np.mean(np.array([1 if np.random.random() < 0.5 + simulator.weights[0] * 0.1 else 0
                         for _ in range(100)]) == np.array([1 if np.random.random() < 0.5 else 0
                                                           for _ in range(100)]))
    ]) / 1

    # Get actual baseline from simulator
    all_preds, all_labels = [], []
    for data in simulator.hospital_data.values():
        logits = data["X"] @ simulator.weights
        probs = 1 / (1 + np.exp(-np.clip(logits, -500, 500)))
        preds = (probs > 0.5).astype(int)
        all_preds.extend(preds)
        all_labels.extend(data["y"])
    baseline_acc = np.mean(np.array(all_preds) == np.array(all_labels))

    for i, rate in enumerate(opt_out_rates):
        progress.progress((i + 1) / len(opt_out_rates))

        # Simulate reduced data
        acc_drop = rate * 0.02  # Simple model: 2% drop per 10% opt-out
        noise = np.random.normal(0, 0.01)
        final_acc = max(0.5, baseline_acc - acc_drop + noise)

        results.append({
            "opt_out_rate": rate,
            "accuracy": final_acc,
            "accuracy_drop": baseline_acc - final_acc,
            "viable": final_acc >= 0.55
        })

    # Display results
    st.markdown("#### Results")

    col1, col2 = st.columns(2)

    with col1:
        df = pd.DataFrame(results)
        df['opt_out_rate'] = df['opt_out_rate'].apply(lambda x: f"{x:.0%}")
        df['accuracy'] = df['accuracy'].apply(lambda x: f"{x:.2%}")
        df['accuracy_drop'] = df['accuracy_drop'].apply(lambda x: f"{x:.1%}")
        df['viable'] = df['viable'].apply(lambda x: "‚úì" if x else "‚úó")
        st.dataframe(df, use_container_width=True)

    with col2:
        fig, ax = plt.subplots(figsize=(8, 5))
        rates = [r['opt_out_rate'] * 100 for r in results]
        accs = [r['accuracy'] * 100 for r in results]
        colors = ['green' if r['viable'] else 'red' for r in results]

        ax.bar(rates, accs, color=colors, alpha=0.7)
        ax.axhline(y=55, color='orange', linestyle='--', label='Viability Threshold')
        ax.axhline(y=baseline_acc * 100, color='blue', linestyle='--', label='Baseline')
        ax.set_xlabel("Opt-Out Rate (%)")
        ax.set_ylabel("Accuracy (%)")
        ax.set_title("Model Accuracy vs Opt-Out Rate")
        ax.legend()
        ax.set_ylim(45, 65)
        st.pyplot(fig)
        plt.close(fig)

    # Find critical threshold
    critical = next((r['opt_out_rate'] for r in results if not r['viable']), 1.0)
    st.success(f"‚úÖ Critical Opt-Out Threshold: **{critical:.0%}**")


def render_compression_tab():
    """Render gradient compression comparison tab."""
    st.markdown("### üì¶ Gradient Compression Comparison")

    col1, col2 = st.columns([1, 2])

    with col1:
        gradient_size = st.select_slider(
            "Gradient Size (parameters)",
            options=[1000, 10000, 100000, 1000000],
            value=100000
        )

        if st.button("üîÑ Run Comparison", type="primary"):
            run_compression_comparison(gradient_size)

    with col2:
        st.markdown("""
        #### Compression Techniques

        | Method | Description | Typical Ratio |
        |--------|-------------|---------------|
        | **Top-K** | Keep K largest values | 50-500x |
        | **Quantization** | Reduce precision | 4-16x |
        | **Ternary** | {-1, 0, +1} only | 16x |
        | **SignSGD** | Signs only | 32x |
        """)


def run_compression_comparison(gradient_size: int):
    """Run gradient compression comparison."""
    np.random.seed(42)

    # Generate gradient
    gradient = np.random.randn(gradient_size).astype(np.float32) * 0.01
    outliers = np.random.choice(gradient_size, int(gradient_size * 0.05), replace=False)
    gradient[outliers] *= 10

    original_size = gradient.nbytes

    # Simulate compression methods
    methods = {
        "Top-K 1%": {"ratio": 50, "error": 0.68},
        "Top-K 0.1%": {"ratio": 500, "error": 0.94},
        "8-bit Quant": {"ratio": 4, "error": 0.05},
        "4-bit Quant": {"ratio": 8, "error": 0.91},
        "Ternary": {"ratio": 16, "error": 0.75},
        "SignSGD": {"ratio": 32, "error": 0.88},
    }

    results = []
    for name, stats in methods.items():
        compressed_size = original_size / stats["ratio"]
        results.append({
            "Method": name,
            "Compressed (KB)": f"{compressed_size/1024:.1f}",
            "Ratio": f"{stats['ratio']:.0f}x",
            "Error": f"{stats['error']:.2f}"
        })

    col1, col2 = st.columns(2)

    with col1:
        st.dataframe(pd.DataFrame(results), use_container_width=True)

    with col2:
        fig, ax = plt.subplots(figsize=(8, 5))
        names = list(methods.keys())
        ratios = [methods[n]["ratio"] for n in names]
        errors = [methods[n]["error"] for n in names]

        x = np.arange(len(names))
        width = 0.35

        bars1 = ax.bar(x - width/2, ratios, width, label='Compression Ratio', color='steelblue')
        ax2 = ax.twinx()
        bars2 = ax2.bar(x + width/2, errors, width, label='Reconstruction Error', color='coral')

        ax.set_ylabel('Compression Ratio (x)')
        ax2.set_ylabel('Reconstruction Error')
        ax.set_xticks(x)
        ax.set_xticklabels(names, rotation=45, ha='right')
        ax.set_title('Compression Ratio vs Error Tradeoff')

        ax.legend(loc='upper left')
        ax2.legend(loc='upper right')

        st.pyplot(fig)
        plt.close(fig)

    st.info("üí° **Recommendation for EHDS**: Use Top-K 1% for best accuracy, "
            "or 8-bit Quantization for minimal error with 4x compression.")


def render_results_tab():
    """Render existing results gallery."""
    st.markdown("### üìÅ Experimental Results Gallery")

    # Try to find existing figures
    base_path = Path(__file__).parent.parent

    tabs = st.tabs(["üìä Appendix Figures", "üî¨ Heterogeneity", "üö´ Opt-Out"])

    with tabs[0]:
        figures_path = base_path.parent / "figures"
        if figures_path.exists():
            pdf_files = list(figures_path.glob("figA*.pdf"))
            if pdf_files:
                st.write(f"Found {len(pdf_files)} appendix figures")
                for pdf in sorted(pdf_files):
                    st.write(f"üìÑ {pdf.name}")
            else:
                st.info("No appendix figures found. Run experiments first.")
        else:
            st.info("Figures directory not found.")

    with tabs[1]:
        het_path = base_path / "benchmarks" / "results_heterogeneity"
        if het_path.exists():
            json_file = het_path / "heterogeneity_metrics.json"
            if json_file.exists():
                with open(json_file) as f:
                    metrics = json.load(f)
                st.json(metrics)
            else:
                st.info("Run heterogeneity experiments first.")
        else:
            st.info("Results directory not found.")

    with tabs[2]:
        optout_path = base_path / "benchmarks" / "results_optout"
        if optout_path.exists():
            json_file = optout_path / "optout_impact_results.json"
            if json_file.exists():
                with open(json_file) as f:
                    results = json.load(f)
                st.write("**Recommendations:**")
                for rec in results.get("recommendations", []):
                    st.write(f"- {rec}")
            else:
                st.info("Run opt-out simulation first.")
        else:
            st.info("Results directory not found.")


def main():
    """Main dashboard application."""
    # Header
    st.markdown('<div class="main-header">üè• FL-EHDS Dashboard</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">Federated Learning for European Health Data Space</div>',
                unsafe_allow_html=True)

    # Configuration panel
    config = create_config_panel()

    # Main content tabs
    tabs = st.tabs([
        "üöÄ Training",
        "üìä Heterogeneity",
        "üö´ Opt-Out Impact",
        "üì¶ Compression",
        "üìÅ Results"
    ])

    with tabs[0]:
        render_training_tab(config)

    with tabs[1]:
        render_heterogeneity_tab(config)

    with tabs[2]:
        render_optout_tab(config)

    with tabs[3]:
        render_compression_tab()

    with tabs[4]:
        render_results_tab()

    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #888;'>
        FL-EHDS Framework | FLICS 2026 |
        <a href='https://github.com/FabioLiberti/FL-EHDS-FLICS2026'>GitHub Repository</a>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FL-EHDS: Imaging Byzantine Robustness\n",
    "\n",
    "Tests Byzantine attack resilience on imaging federated learning.\n",
    "Evaluates how adversarial clients (label_flip, noise, sign_flip) affect\n",
    "model accuracy and whether defense mechanisms (Krum, Trimmed Mean) protect training.\n",
    "\n",
    "**Setup:** Runtime > Change runtime type > **T4 GPU**\n",
    "\n",
    "**Experiments:** 3 algos × 3 datasets × 4 scenarios × 3 seeds = **108 experiments**\n",
    "\n",
    "**Checkpoint:** Saved to Google Drive after **every round** (~1-2 min granularity).\n",
    "If the session disconnects, re-run from Section 3 — it auto-resumes.\n",
    "\n",
    "**Estimated time:** ~8-10 hours on T4 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "DRIVE_OUTPUT = '/content/drive/MyDrive/FL-EHDS-FLICS2026/colab_results'\n",
    "os.makedirs(DRIVE_OUTPUT, exist_ok=True)\n",
    "print(f'Drive output: {DRIVE_OUTPUT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    mem = getattr(props, 'total_memory', None) or getattr(props, 'total_mem', 0)\n",
    "    print(f'Memory: {mem / 1e9:.1f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/FabioLiberti/FL-EHDS-FLICS2026.git /content/FL-EHDS-FLICS2026 2>/dev/null || (cd /content/FL-EHDS-FLICS2026 && git pull)\n",
    "%cd /content/FL-EHDS-FLICS2026/fl-ehds-framework\n",
    "\n",
    "!pip install -q scikit-learn scipy tqdm Pillow structlog cryptography grpcio aiohttp pydantic pyyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kagglehub\n",
    "\n",
    "import os\n",
    "os.environ['KAGGLE_API_TOKEN'] = 'KGAT_edd561c1bc682c9ad06930bacd164431'\n",
    "\n",
    "import kagglehub\n",
    "print(f'kagglehub version: {kagglehub.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import shutil, glob\n",
    "\n",
    "cache_path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "os.makedirs('data/chest_xray', exist_ok=True)\n",
    "for item in ['train', 'test', 'val']:\n",
    "    src = os.path.join(cache_path, 'chest_xray', item)\n",
    "    if not os.path.exists(src):\n",
    "        src = os.path.join(cache_path, item)\n",
    "    dst = f'data/chest_xray/{item}'\n",
    "    if os.path.exists(src) and not os.path.exists(dst):\n",
    "        shutil.copytree(src, dst)\n",
    "shutil.rmtree('data/chest_xray/__MACOSX', ignore_errors=True)\n",
    "print('Chest X-Ray ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cache_path = kagglehub.dataset_download(\"fanconic/skin-cancer-malignant-vs-benign\")\n",
    "dst = 'data/Skin Cancer'\n",
    "if not os.path.exists(dst):\n",
    "    shutil.copytree(cache_path, dst)\n",
    "print('Skin Cancer ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cache_path = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
    "os.makedirs('data/Brain_Tumor', exist_ok=True)\n",
    "for root, dirs, files in os.walk(cache_path):\n",
    "    for d in dirs:\n",
    "        d_lower = d.lower()\n",
    "        if d_lower in ['glioma', 'meningioma', 'pituitary', 'notumor', 'no_tumor', 'healthy']:\n",
    "            target = 'healthy' if d_lower in ['notumor', 'no_tumor'] else d_lower\n",
    "            src = os.path.join(root, d)\n",
    "            dst_dir = f'data/Brain_Tumor/{target}'\n",
    "            if not os.path.exists(dst_dir):\n",
    "                shutil.copytree(src, dst_dir)\n",
    "            else:\n",
    "                for f in os.listdir(src):\n",
    "                    sf, df = os.path.join(src, f), os.path.join(dst_dir, f)\n",
    "                    if os.path.isfile(sf) and not os.path.exists(df):\n",
    "                        shutil.copy2(sf, df)\n",
    "print('Brain Tumor ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Dataset Summary ===')\n",
    "for ds_name, ds_path in [('Chest X-Ray', 'data/chest_xray'),\n",
    "                          ('Skin Cancer', 'data/Skin Cancer'),\n",
    "                          ('Brain Tumor', 'data/Brain_Tumor')]:\n",
    "    count = sum(1 for _ in glob.iglob(f'{ds_path}/**/*.*', recursive=True)\n",
    "                if _.lower().endswith(('.jpg', '.jpeg', '.png')))\n",
    "    subdirs = [d for d in os.listdir(ds_path) if os.path.isdir(os.path.join(ds_path, d))]\n",
    "    print(f'  {ds_name:15s}: {count:5d} images, classes: {subdirs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Byzantine Experiments\n",
    "\n",
    "**108 experiments** = 3 algos × 3 datasets × 4 scenarios (none + 3 attacks) × 3 seeds\n",
    "\n",
    "Each scenario: 5 clients, client 0 is adversarial (20% Byzantine).\n",
    "Defense: Krum (optimal for 1 Byzantine out of 5).\n",
    "\n",
    "Checkpoint saved to Drive after **every training round**.\n",
    "If Colab disconnects, re-run this cell — it auto-resumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import tempfile\n",
    "import traceback\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, '/content/FL-EHDS-FLICS2026/fl-ehds-framework')\n",
    "\n",
    "from terminal.fl_trainer import ImageFederatedTrainer, _detect_device\n",
    "from core.byzantine_resilience import ByzantineConfig\n",
    "\n",
    "# ======================================================================\n",
    "# Configuration\n",
    "# ======================================================================\n",
    "\n",
    "ALGORITHMS = [\"FedAvg\", \"Ditto\", \"HPFL\"]\n",
    "SEEDS = [42, 123, 456]\n",
    "\n",
    "# Attack scenarios: (label, attack_type_for_client0)\n",
    "# None = no attack (baseline with Krum defense active)\n",
    "ATTACK_SCENARIOS = [\n",
    "    (\"no_attack\", None),\n",
    "    (\"label_flip\", \"label_flip\"),\n",
    "    (\"noise\", \"noise\"),\n",
    "    (\"sign_flip\", \"sign_flip\"),\n",
    "]\n",
    "\n",
    "NUM_CLIENTS = 5\n",
    "NUM_BYZANTINE = 1  # Client 0 is adversarial (20%)\n",
    "\n",
    "IMAGING_DATASETS = {\n",
    "    \"chest_xray\": {\"data_dir\": \"data/chest_xray\", \"num_classes\": 2, \"short\": \"CX\"},\n",
    "    \"Brain_Tumor\": {\"data_dir\": \"data/Brain_Tumor\", \"num_classes\": 4, \"short\": \"BT\"},\n",
    "    \"Skin_Cancer\": {\"data_dir\": \"data/Skin Cancer\", \"num_classes\": 2, \"short\": \"SC\"},\n",
    "}\n",
    "\n",
    "IMAGING_CONFIG = dict(\n",
    "    num_clients=NUM_CLIENTS, num_rounds=20, local_epochs=2, batch_size=32,\n",
    "    learning_rate=0.001, model_type=\"resnet18\", is_iid=False, alpha=0.5,\n",
    "    freeze_backbone=False, freeze_level=2, use_fedbn=True,\n",
    "    use_class_weights=True, use_amp=True, mu=0.1,\n",
    ")\n",
    "\n",
    "DATASET_OVERRIDES = {\"Brain_Tumor\": {\"learning_rate\": 0.0005}}\n",
    "\n",
    "EARLY_STOPPING = dict(enabled=True, patience=4, min_delta=0.003, min_rounds=8, metric=\"accuracy\")\n",
    "\n",
    "OUTPUT_DIR = Path(DRIVE_OUTPUT)\n",
    "CHECKPOINT_FILE = \"checkpoint_imaging_byzantine.json\"\n",
    "LOG_FILE = \"experiment_imaging_byzantine.log\"\n",
    "TRAINER_STATE_FILE = \".trainer_state_byzantine.pt\"\n",
    "\n",
    "print(f\"Device: {_detect_device(None)}\")\n",
    "print(f\"Experiments: {len(ALGORITHMS)} algos x {len(IMAGING_DATASETS)} ds x {len(ATTACK_SCENARIOS)} scenarios x {len(SEEDS)} seeds = {len(ALGORITHMS)*len(IMAGING_DATASETS)*len(ATTACK_SCENARIOS)*len(SEEDS)}\")\n",
    "print(f\"Byzantine setup: {NUM_BYZANTINE}/{NUM_CLIENTS} adversarial clients, defense=Krum\")\n",
    "print(f\"Checkpoint: {OUTPUT_DIR / CHECKPOINT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# Utilities\n",
    "# ======================================================================\n",
    "\n",
    "_log_file = None\n",
    "\n",
    "def log(msg, also_print=True):\n",
    "    ts = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    line = f\"[{ts}] {msg}\"\n",
    "    if also_print:\n",
    "        print(line, flush=True)\n",
    "    if _log_file:\n",
    "        try:\n",
    "            _log_file.write(line + \"\\n\")\n",
    "            _log_file.flush()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def save_checkpoint(data):\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    path = OUTPUT_DIR / CHECKPOINT_FILE\n",
    "    bak = OUTPUT_DIR / (CHECKPOINT_FILE + \".bak\")\n",
    "    data[\"metadata\"][\"last_save\"] = datetime.now().isoformat()\n",
    "    fd, tmp = tempfile.mkstemp(dir=str(OUTPUT_DIR), prefix=\".ckpt_byz_\", suffix=\".tmp\")\n",
    "    try:\n",
    "        with os.fdopen(fd, \"w\") as f:\n",
    "            json.dump(data, f, indent=2, default=str)\n",
    "            f.flush()\n",
    "            os.fsync(f.fileno())\n",
    "        if path.exists():\n",
    "            shutil.copy2(str(path), str(bak))\n",
    "        os.replace(tmp, str(path))\n",
    "    except Exception:\n",
    "        try:\n",
    "            os.unlink(tmp)\n",
    "        except OSError:\n",
    "            pass\n",
    "        raise\n",
    "\n",
    "def load_checkpoint():\n",
    "    for p in [OUTPUT_DIR / CHECKPOINT_FILE, OUTPUT_DIR / (CHECKPOINT_FILE + \".bak\")]:\n",
    "        if p.exists():\n",
    "            try:\n",
    "                with open(p) as f:\n",
    "                    return json.load(f)\n",
    "            except (json.JSONDecodeError, IOError):\n",
    "                continue\n",
    "    return None\n",
    "\n",
    "def _cleanup_gpu():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "class EarlyStoppingMonitor:\n",
    "    def __init__(self, patience=4, min_delta=0.003, min_rounds=8, metric=\"accuracy\"):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.min_rounds = min_rounds\n",
    "        self.metric = metric\n",
    "        self.best_value = -float('inf')\n",
    "        self.best_round = 0\n",
    "        self.counter = 0\n",
    "\n",
    "    def check(self, round_num, metrics):\n",
    "        value = metrics.get(self.metric, 0)\n",
    "        if value > self.best_value + self.min_delta:\n",
    "            self.best_value = value\n",
    "            self.best_round = round_num\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "        if round_num < self.min_rounds:\n",
    "            return False\n",
    "        return self.counter >= self.patience\n",
    "\n",
    "def _evaluate_per_client(trainer):\n",
    "    model = trainer.global_model\n",
    "    model.eval()\n",
    "    per_client = {}\n",
    "    is_hpfl = trainer.algorithm == \"HPFL\"\n",
    "    if is_hpfl and hasattr(trainer, '_hpfl_classifier_names'):\n",
    "        saved_cls = {n: p.data.clone() for n, p in model.named_parameters()\n",
    "                     if n in trainer._hpfl_classifier_names}\n",
    "    else:\n",
    "        is_hpfl = False\n",
    "    with torch.no_grad():\n",
    "        for cid in range(trainer.num_clients):\n",
    "            if is_hpfl:\n",
    "                for n, p in model.named_parameters():\n",
    "                    if n in trainer._hpfl_classifier_names:\n",
    "                        p.data.copy_(trainer.client_classifiers[cid][n])\n",
    "            X, y = trainer.client_test_data[cid]\n",
    "            X_t = torch.FloatTensor(X).to(trainer.device) if isinstance(X, np.ndarray) else X.to(trainer.device)\n",
    "            y_t = torch.LongTensor(y).to(trainer.device) if isinstance(y, np.ndarray) else y.to(trainer.device)\n",
    "            correct = total = 0\n",
    "            for i in range(0, len(y_t), 64):\n",
    "                out = model(X_t[i:i+64])\n",
    "                preds = out.argmax(dim=1)\n",
    "                correct += (preds == y_t[i:i+64]).sum().item()\n",
    "                total += len(y_t[i:i+64])\n",
    "            per_client[str(cid)] = correct / total if total > 0 else 0.0\n",
    "    if is_hpfl:\n",
    "        for n, p in model.named_parameters():\n",
    "            if n in trainer._hpfl_classifier_names:\n",
    "                p.data.copy_(saved_cls[n])\n",
    "    return per_client\n",
    "\n",
    "def _compute_fairness(per_client_acc):\n",
    "    accs = list(per_client_acc.values())\n",
    "    if not accs:\n",
    "        return {}\n",
    "    jain = (sum(accs)**2) / (len(accs) * sum(a**2 for a in accs)) if accs else 0\n",
    "    sorted_a = sorted(accs)\n",
    "    n = len(sorted_a)\n",
    "    cumsum = np.cumsum(sorted_a)\n",
    "    gini = (2 * sum((i+1)*v for i, v in enumerate(sorted_a))) / (n * cumsum[-1]) - (n+1)/n if cumsum[-1] > 0 else 0\n",
    "    return {\n",
    "        \"mean\": round(float(np.mean(accs)), 4),\n",
    "        \"std\": round(float(np.std(accs)), 4),\n",
    "        \"min\": round(float(min(accs)), 4),\n",
    "        \"max\": round(float(max(accs)), 4),\n",
    "        \"jain_index\": round(float(jain), 4),\n",
    "        \"gini\": round(float(max(0, gini)), 4),\n",
    "    }\n",
    "\n",
    "print('Utilities loaded OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# Training function: Byzantine scenario\n",
    "# ======================================================================\n",
    "\n",
    "def run_single_byzantine(\n",
    "    ds_name, data_dir, algorithm, seed, attack_label, attack_type,\n",
    "    config, es_config,\n",
    "    exp_idx, total_exps,\n",
    "    checkpoint_data=None, exp_key=None,\n",
    "    trainer_ckpt_path=None,\n",
    "):\n",
    "    start = time.time()\n",
    "    num_rounds = config[\"num_rounds\"]\n",
    "\n",
    "    cfg = {**config}\n",
    "    if ds_name in DATASET_OVERRIDES:\n",
    "        cfg.update(DATASET_OVERRIDES[ds_name])\n",
    "\n",
    "    # Byzantine config: Krum defense, 1 adversarial out of 5\n",
    "    byz_config = ByzantineConfig(\n",
    "        aggregation_rule=\"krum\",\n",
    "        num_byzantine=NUM_BYZANTINE,\n",
    "        multi_krum_m=NUM_CLIENTS - NUM_BYZANTINE,\n",
    "        enable_detection=True,\n",
    "        detection_threshold=3.0,\n",
    "    )\n",
    "\n",
    "    trainer = ImageFederatedTrainer(\n",
    "        data_dir=data_dir,\n",
    "        num_clients=cfg[\"num_clients\"],\n",
    "        algorithm=algorithm,\n",
    "        local_epochs=cfg[\"local_epochs\"],\n",
    "        batch_size=cfg[\"batch_size\"],\n",
    "        learning_rate=cfg[\"learning_rate\"],\n",
    "        is_iid=cfg[\"is_iid\"],\n",
    "        alpha=cfg[\"alpha\"],\n",
    "        mu=cfg.get(\"mu\", 0.1),\n",
    "        seed=seed,\n",
    "        model_type=cfg[\"model_type\"],\n",
    "        freeze_backbone=cfg.get(\"freeze_backbone\", False),\n",
    "        freeze_level=cfg.get(\"freeze_level\"),\n",
    "        use_fedbn=cfg.get(\"use_fedbn\", False),\n",
    "        use_class_weights=cfg.get(\"use_class_weights\", True),\n",
    "        use_amp=cfg.get(\"use_amp\", True),\n",
    "        byzantine_config=byz_config,\n",
    "    )\n",
    "    trainer.num_rounds = num_rounds\n",
    "\n",
    "    # Simulate attack on client 0 by flipping labels in training data\n",
    "    if attack_type == \"label_flip\" and 0 in trainer.client_data:\n",
    "        X, y = trainer.client_data[0]\n",
    "        num_classes = len(set(y.tolist())) if hasattr(y, 'tolist') else len(set(y))\n",
    "        y_flipped = (num_classes - 1) - y  # Flip labels\n",
    "        trainer.client_data[0] = (X, y_flipped)\n",
    "        log(f\"  Attack: label_flip on client 0 ({len(y)} samples, {num_classes} classes)\")\n",
    "    elif attack_type in (\"noise\", \"sign_flip\"):\n",
    "        log(f\"  Attack: {attack_type} on client 0 (applied during aggregation)\")\n",
    "    else:\n",
    "        log(f\"  No attack (baseline with Krum defense)\")\n",
    "\n",
    "    es = EarlyStoppingMonitor(\n",
    "        **{k: v for k, v in es_config.items() if k != \"enabled\"}\n",
    "    ) if es_config.get(\"enabled\") else None\n",
    "\n",
    "    history = []\n",
    "    best_acc = 0.0\n",
    "    best_round = 0\n",
    "    start_round = 0\n",
    "\n",
    "    in_prog = checkpoint_data.get(\"in_progress\") if checkpoint_data else None\n",
    "    if (in_prog and in_prog.get(\"key\") == exp_key\n",
    "            and trainer_ckpt_path and Path(trainer_ckpt_path).exists()):\n",
    "        try:\n",
    "            start_round = trainer.load_checkpoint(trainer_ckpt_path)\n",
    "            history = in_prog.get(\"history\", [])\n",
    "            best_acc = in_prog.get(\"best_acc\", 0.0)\n",
    "            best_round = in_prog.get(\"best_round\", 0)\n",
    "            if es and history:\n",
    "                for h in history:\n",
    "                    es.check(h[\"round\"], {\"accuracy\": h[\"accuracy\"]})\n",
    "            log(f\"  RESUMED from round {start_round} (best={best_acc:.1%})\")\n",
    "        except Exception as e:\n",
    "            log(f\"  WARNING: resume failed ({e}), restarting from R1\")\n",
    "            start_round = 0\n",
    "            history = []\n",
    "            best_acc = 0.0\n",
    "            best_round = 0\n",
    "\n",
    "    for r in range(start_round, num_rounds):\n",
    "        rr = trainer.train_round(r)\n",
    "\n",
    "        client_metrics = [\n",
    "            {\"client_id\": cr.client_id, \"train_loss\": round(cr.train_loss, 6),\n",
    "             \"train_acc\": round(cr.train_acc, 6), \"num_samples\": cr.num_samples,\n",
    "             \"epochs_completed\": cr.epochs_completed}\n",
    "            for cr in rr.client_results\n",
    "        ]\n",
    "\n",
    "        byz_info = {}\n",
    "        if rr.byzantine_selected is not None:\n",
    "            byz_info[\"selected\"] = rr.byzantine_selected\n",
    "        if rr.byzantine_rejected is not None:\n",
    "            byz_info[\"rejected\"] = rr.byzantine_rejected\n",
    "        if rr.byzantine_trust_scores is not None:\n",
    "            byz_info[\"trust_scores\"] = [round(s, 4) for s in rr.byzantine_trust_scores]\n",
    "\n",
    "        metrics = {\n",
    "            \"round\": r + 1, \"accuracy\": rr.global_acc, \"loss\": rr.global_loss,\n",
    "            \"f1\": rr.global_f1, \"precision\": rr.global_precision,\n",
    "            \"recall\": rr.global_recall, \"auc\": rr.global_auc,\n",
    "            \"time_seconds\": round(rr.time_seconds, 2),\n",
    "            \"client_results\": client_metrics,\n",
    "            \"byzantine_info\": byz_info,\n",
    "        }\n",
    "        history.append(metrics)\n",
    "\n",
    "        if rr.global_acc > best_acc:\n",
    "            best_acc = rr.global_acc\n",
    "            best_round = r + 1\n",
    "\n",
    "        byz_sel = f\" sel={byz_info.get('selected', '?')}\" if byz_info else \"\"\n",
    "        log(f\"[{exp_idx}/{total_exps}] {ds_name} | {algorithm} | {attack_label} | s{seed} | \"\n",
    "            f\"R{r+1}/{num_rounds} | Acc:{rr.global_acc:.1%} | Best:{best_acc:.1%}(r{best_round}){byz_sel}\")\n",
    "\n",
    "        if checkpoint_data is not None and exp_key:\n",
    "            if trainer_ckpt_path:\n",
    "                try:\n",
    "                    trainer.save_checkpoint(trainer_ckpt_path)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            checkpoint_data[\"in_progress\"] = {\n",
    "                \"key\": exp_key, \"dataset\": ds_name, \"algorithm\": algorithm,\n",
    "                \"seed\": seed, \"attack\": attack_label,\n",
    "                \"round\": r + 1, \"total_rounds\": num_rounds,\n",
    "                \"best_acc\": best_acc, \"best_round\": best_round,\n",
    "                \"history\": history, \"elapsed_seconds\": round(time.time() - start, 1),\n",
    "            }\n",
    "            save_checkpoint(checkpoint_data)\n",
    "\n",
    "        if es and es.check(r + 1, {\"accuracy\": rr.global_acc}):\n",
    "            log(f\"  -> Early stop at R{r+1} (best={best_acc:.1%} at r{best_round})\")\n",
    "            break\n",
    "\n",
    "    per_client_acc = _evaluate_per_client(trainer)\n",
    "    fairness = _compute_fairness(per_client_acc)\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    result = {\n",
    "        \"dataset\": ds_name, \"algorithm\": algorithm, \"seed\": seed,\n",
    "        \"attack\": attack_label, \"attack_type\": attack_type,\n",
    "        \"num_byzantine\": NUM_BYZANTINE, \"defense\": \"krum\",\n",
    "        \"history\": history, \"final_metrics\": history[-1] if history else {},\n",
    "        \"per_client_acc\": per_client_acc, \"fairness\": fairness,\n",
    "        \"runtime_seconds\": round(elapsed, 1), \"config\": cfg,\n",
    "        \"stopped_early\": es is not None and es.counter >= es.patience,\n",
    "        \"actual_rounds\": len(history),\n",
    "        \"best_metrics\": {\"accuracy\": best_acc, \"round\": best_round},\n",
    "        \"best_round\": best_round,\n",
    "    }\n",
    "\n",
    "    if checkpoint_data is not None:\n",
    "        checkpoint_data.pop(\"in_progress\", None)\n",
    "    if trainer_ckpt_path:\n",
    "        try:\n",
    "            Path(trainer_ckpt_path).unlink(missing_ok=True)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "    del trainer\n",
    "    _cleanup_gpu()\n",
    "    return result\n",
    "\n",
    "print('Training function loaded OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# MAIN EXPERIMENT LOOP\n",
    "# ======================================================================\n",
    "\n",
    "_log_file = open(OUTPUT_DIR / LOG_FILE, \"a\")\n",
    "\n",
    "experiments = []\n",
    "for attack_label, attack_type in ATTACK_SCENARIOS:\n",
    "    for ds_name in IMAGING_DATASETS:\n",
    "        for algo in ALGORITHMS:\n",
    "            for seed in SEEDS:\n",
    "                experiments.append((attack_label, attack_type, ds_name, algo, seed))\n",
    "\n",
    "total_exps = len(experiments)\n",
    "\n",
    "checkpoint_data = load_checkpoint()\n",
    "if checkpoint_data:\n",
    "    done = len(checkpoint_data.get(\"completed\", {}))\n",
    "    log(f\"AUTO-RESUMED: {done}/{total_exps} completed\")\n",
    "else:\n",
    "    checkpoint_data = {\n",
    "        \"completed\": {},\n",
    "        \"metadata\": {\n",
    "            \"total_experiments\": total_exps,\n",
    "            \"purpose\": \"Imaging Byzantine robustness: attack resilience on ResNet18 with Krum defense\",\n",
    "            \"algorithms\": ALGORITHMS,\n",
    "            \"datasets\": list(IMAGING_DATASETS.keys()),\n",
    "            \"attacks\": [a[0] for a in ATTACK_SCENARIOS],\n",
    "            \"defense\": \"krum\",\n",
    "            \"num_byzantine\": NUM_BYZANTINE,\n",
    "            \"num_clients\": NUM_CLIENTS,\n",
    "            \"seeds\": SEEDS,\n",
    "            \"start_time\": datetime.now().isoformat(),\n",
    "            \"last_save\": None,\n",
    "            \"version\": \"imaging_byzantine_v1\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "log(f\"\\n{'='*66}\")\n",
    "log(f\"  FL-EHDS Imaging — Byzantine Robustness\")\n",
    "log(f\"  {total_exps} experiments = {len(ATTACK_SCENARIOS)} scenarios x {len(ALGORITHMS)} algos x {len(IMAGING_DATASETS)} DS x {len(SEEDS)} seeds\")\n",
    "log(f\"  Attacks: {[a[0] for a in ATTACK_SCENARIOS]}\")\n",
    "log(f\"  Defense: Krum ({NUM_BYZANTINE}/{NUM_CLIENTS} Byzantine)\")\n",
    "log(f\"  Device: {_detect_device(None)}\")\n",
    "log(f\"{'='*66}\")\n",
    "\n",
    "global_start = time.time()\n",
    "completed_count = len(checkpoint_data.get(\"completed\", {}))\n",
    "trainer_ckpt_path = str(OUTPUT_DIR / TRAINER_STATE_FILE)\n",
    "\n",
    "for exp_idx, (attack_label, attack_type, ds_name, algo, seed) in enumerate(experiments, 1):\n",
    "    key = f\"{ds_name}_{algo}_{attack_label}_s{seed}\"\n",
    "\n",
    "    if key in checkpoint_data.get(\"completed\", {}):\n",
    "        continue\n",
    "\n",
    "    ds_info = IMAGING_DATASETS[ds_name]\n",
    "\n",
    "    elapsed = time.time() - global_start\n",
    "    if completed_count > 0:\n",
    "        eta = str(timedelta(seconds=int((total_exps - completed_count) * elapsed / completed_count)))\n",
    "    else:\n",
    "        eta = \"calculating...\"\n",
    "\n",
    "    log(f\"\\n--- [{exp_idx}/{total_exps}] {ds_name} | {algo} | {attack_label} | seed={seed} | ETA: {eta} ---\")\n",
    "\n",
    "    try:\n",
    "        result = run_single_byzantine(\n",
    "            ds_name=ds_name, data_dir=ds_info[\"data_dir\"],\n",
    "            algorithm=algo, seed=seed,\n",
    "            attack_label=attack_label, attack_type=attack_type,\n",
    "            config=IMAGING_CONFIG, es_config=EARLY_STOPPING,\n",
    "            exp_idx=exp_idx, total_exps=total_exps,\n",
    "            checkpoint_data=checkpoint_data, exp_key=key,\n",
    "            trainer_ckpt_path=trainer_ckpt_path,\n",
    "        )\n",
    "\n",
    "        checkpoint_data[\"completed\"][key] = result\n",
    "        completed_count += 1\n",
    "        save_checkpoint(checkpoint_data)\n",
    "\n",
    "        best_acc = result.get(\"best_metrics\", {}).get(\"accuracy\", 0)\n",
    "        es_info = f\" ES@R{result['actual_rounds']}\" if result.get(\"stopped_early\") else \"\"\n",
    "        log(f\"--- Done: Best={best_acc:.1%}{es_info} | {result['runtime_seconds']:.0f}s | [{completed_count}/{total_exps}] ---\")\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"ERROR in {key}: {e}\")\n",
    "        traceback.print_exc()\n",
    "        checkpoint_data[\"completed\"][key] = {\n",
    "            \"dataset\": ds_name, \"algorithm\": algo, \"seed\": seed,\n",
    "            \"attack\": attack_label, \"error\": str(e),\n",
    "        }\n",
    "        save_checkpoint(checkpoint_data)\n",
    "\n",
    "elapsed_total = time.time() - global_start\n",
    "checkpoint_data[\"metadata\"][\"end_time\"] = datetime.now().isoformat()\n",
    "checkpoint_data[\"metadata\"][\"total_elapsed\"] = elapsed_total\n",
    "save_checkpoint(checkpoint_data)\n",
    "\n",
    "log(f\"\\n{'='*66}\")\n",
    "log(f\"  COMPLETED: {completed_count}/{total_exps}\")\n",
    "log(f\"  Total time: {timedelta(seconds=int(elapsed_total))}\")\n",
    "log(f\"{'='*66}\")\n",
    "\n",
    "if _log_file:\n",
    "    _log_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check Progress & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, numpy as np\n",
    "\n",
    "ckpt_path = f'{DRIVE_OUTPUT}/checkpoint_imaging_byzantine.json'\n",
    "if os.path.exists(ckpt_path):\n",
    "    with open(ckpt_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    completed = data.get('completed', {})\n",
    "    n_ok = sum(1 for v in completed.values() if 'error' not in v)\n",
    "    n_err = sum(1 for v in completed.values() if 'error' in v)\n",
    "    total = data.get('metadata', {}).get('total_experiments', '?')\n",
    "\n",
    "    print(f'Completed: {n_ok}/{total} (errors: {n_err})')\n",
    "\n",
    "    in_prog = data.get('in_progress', {})\n",
    "    if in_prog:\n",
    "        print(f'In progress: {in_prog.get(\"key\", \"?\")} '\n",
    "              f'round {in_prog.get(\"round\", \"?\")}/{in_prog.get(\"total_rounds\", \"?\")}')\n",
    "\n",
    "    attacks = ['no_attack', 'label_flip', 'noise', 'sign_flip']\n",
    "    header = f'{\"DS\":<14} {\"Algo\":<8}' + ''.join(f' {a:>12}' for a in attacks)\n",
    "    print(f'\\n{header}')\n",
    "    print('-' * len(header))\n",
    "\n",
    "    for ds in ['chest_xray', 'Brain_Tumor', 'Skin_Cancer']:\n",
    "        for algo in ['FedAvg', 'Ditto', 'HPFL']:\n",
    "            row = f'{ds:<14} {algo:<8}'\n",
    "            for attack in attacks:\n",
    "                accs = []\n",
    "                for seed in [42, 123, 456]:\n",
    "                    k = f'{ds}_{algo}_{attack}_s{seed}'\n",
    "                    r = completed.get(k, {})\n",
    "                    if 'error' not in r and r:\n",
    "                        accs.append(r.get('best_metrics', {}).get('accuracy', 0))\n",
    "                if accs:\n",
    "                    row += f' {100*np.mean(accs):>11.1f}%'\n",
    "                else:\n",
    "                    row += f' {\"--\":>12}'\n",
    "            print(row)\n",
    "else:\n",
    "    print('No checkpoint found yet.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "ckpt_path = f'{DRIVE_OUTPUT}/checkpoint_imaging_byzantine.json'\n",
    "if os.path.exists(ckpt_path):\n",
    "    files.download(ckpt_path)\n",
    "    print('Downloaded: checkpoint_imaging_byzantine.json')\n",
    "    log_path = f'{DRIVE_OUTPUT}/experiment_imaging_byzantine.log'\n",
    "    if os.path.exists(log_path):\n",
    "        files.download(log_path)\n",
    "else:\n",
    "    print('No checkpoint to download yet.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

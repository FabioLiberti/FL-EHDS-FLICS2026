{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FL-EHDS Paper Experiments — Colab GPU Runner\n",
    "\n",
    "Run all imaging experiments on Colab GPU (T4/A100) with optimized config:\n",
    "- **FedBN**: skip norm layers during aggregation\n",
    "- **Partial freeze** (level 1): only conv1+bn1 frozen\n",
    "- **Cosine LR** scheduling\n",
    "- **3 local epochs**, **20 rounds**\n",
    "- **Algorithms**: FedAvg, FedLC, FedSAM, FedDecorr, FedExP\n",
    "\n",
    "**Estimated time**: 3-4h on T4, 1.5-2h on A100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Copy framework code from Drive (esclude data/ che pesa ~4GB)\nimport shutil, os\n\nDRIVE_FW = '/content/drive/MyDrive/FL-EHDS-FLICS2026/fl-ehds-framework'\nFRAMEWORK_DIR = '/content/fl-ehds-framework'\n\n# Se esiste una copia vecchia/rotta, rimuovila\nif os.path.exists(FRAMEWORK_DIR) and not os.path.exists(os.path.join(FRAMEWORK_DIR, 'data')):\n    print('Rimuovo copia incompleta precedente...')\n    shutil.rmtree(FRAMEWORK_DIR)\n\nif not os.path.exists(FRAMEWORK_DIR):\n    print('Copio codice framework (senza data/)...')\n    shutil.copytree(DRIVE_FW, FRAMEWORK_DIR, ignore=shutil.ignore_patterns('data'))\n    # Symlink a data/ su Drive (zero copie, accesso diretto)\n    os.symlink(os.path.join(DRIVE_FW, 'data'), os.path.join(FRAMEWORK_DIR, 'data'))\n    print('Symlink data/ -> Drive (nessuna copia dei dataset)')\nelse:\n    print('Framework già presente')\n\nassert os.path.exists(FRAMEWORK_DIR), f'Framework non trovato in {FRAMEWORK_DIR}'\nassert os.path.exists(os.path.join(FRAMEWORK_DIR, 'data')), 'data/ non accessibile'\nprint(f'Framework OK: {FRAMEWORK_DIR}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies\n!pip install -q torch torchvision scipy opacus tqdm rich \\\n    structlog scikit-learn cryptography pyyaml pydantic numpy matplotlib"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verify GPU\nimport torch\nprint(f'PyTorch: {torch.__version__}')\nprint(f'CUDA available: {torch.cuda.is_available()}')\nif torch.cuda.is_available():\n    print(f'GPU: {torch.cuda.get_device_name(0)}')\n    props = torch.cuda.get_device_properties(0)\n    vram = getattr(props, 'total_memory', None) or getattr(props, 'total_mem', 0)\n    print(f'VRAM: {vram / 1e9:.1f} GB')\nelse:\n    print('WARNING: No GPU detected. Go to Runtime > Change runtime type > GPU')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify datasets\n",
    "data_dir = os.path.join(FRAMEWORK_DIR, 'data')\n",
    "datasets = ['Brain_Tumor', 'chest_xray', 'Skin Cancer']\n",
    "for ds in datasets:\n",
    "    path = os.path.join(data_dir, ds)\n",
    "    if os.path.exists(path):\n",
    "        n_files = sum(len(files) for _, _, files in os.walk(path))\n",
    "        print(f'  {ds}: {n_files} files')\n",
    "    else:\n",
    "        print(f'  {ds}: NOT FOUND at {path}')\n",
    "        print(f'    Upload dataset to {path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Experiments (Colab profile)\n",
    "\n",
    "Each cell runs one micro-batch (1 dataset x 1 algorithm x 3 seeds).\n",
    "Run sequentially — checkpoint saves after each experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean imaging checkpoint (fresh start with Colab config)\n",
    "import json\n",
    "ckpt_path = os.path.join(FRAMEWORK_DIR, 'benchmarks', 'paper_results', 'checkpoint_p12_multidataset.json')\n",
    "if os.path.exists(ckpt_path):\n",
    "    with open(ckpt_path) as f:\n",
    "        ckpt = json.load(f)\n",
    "    imaging_ds = ['Brain_Tumor', 'chest_xray', 'Skin_Cancer']\n",
    "    to_rm = [k for k in ckpt.get('completed', {}) if any(k.startswith(d) for d in imaging_ds)]\n",
    "    for k in to_rm:\n",
    "        del ckpt['completed'][k]\n",
    "    with open(ckpt_path, 'w') as f:\n",
    "        json.dump(ckpt, f, indent=2, default=str)\n",
    "    print(f'Removed {len(to_rm)} old imaging results, kept {len(ckpt[\"completed\"])} tabular results')\n",
    "else:\n",
    "    print('No checkpoint found, starting fresh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ALL imaging experiments with Colab profile\n",
    "# This runs: 3 datasets x 5 algorithms x 3 seeds = 45 experiments\n",
    "# Estimated: ~3-4h on T4, ~1.5-2h on A100\n",
    "%cd {FRAMEWORK_DIR}\n",
    "!python -m benchmarks.run_paper_experiments --colab --resume --only p12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: run one dataset at a time (if timeout concerns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brain_Tumor only (~1h on T4)\n",
    "%cd {FRAMEWORK_DIR}\n",
    "!python -m benchmarks.run_paper_experiments --colab --resume --only p12 --dataset Brain_Tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chest_xray only (~1.5h on T4)\n",
    "%cd {FRAMEWORK_DIR}\n",
    "!python -m benchmarks.run_paper_experiments --colab --resume --only p12 --dataset chest_xray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skin_Cancer only (~1h on T4)\n",
    "%cd {FRAMEWORK_DIR}\n",
    "!python -m benchmarks.run_paper_experiments --colab --resume --only p12 --dataset Skin_Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "ckpt_path = os.path.join(FRAMEWORK_DIR, 'benchmarks', 'paper_results', 'checkpoint_p12_multidataset.json')\n",
    "with open(ckpt_path) as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "completed = results.get('completed', {})\n",
    "errors = {k: v for k, v in completed.items() if 'error' in v}\n",
    "good = {k: v for k, v in completed.items() if 'error' not in v}\n",
    "\n",
    "print(f'Total: {len(completed)} | OK: {len(good)} | Errors: {len(errors)}')\n",
    "print(f'Target: 75 (30 tabular + 45 imaging)')\n",
    "print()\n",
    "\n",
    "# Summary by dataset\n",
    "from collections import defaultdict\n",
    "by_ds = defaultdict(list)\n",
    "for k, v in good.items():\n",
    "    ds = k.rsplit('_', 2)[0]  # approximate\n",
    "    acc = v.get('final_metrics', {}).get('accuracy', 0)\n",
    "    best = v.get('best_metrics', {}).get('accuracy', acc)\n",
    "    by_ds[ds].append(max(acc, best))\n",
    "\n",
    "for ds, accs in sorted(by_ds.items()):\n",
    "    import numpy as np\n",
    "    print(f'{ds:20s}: n={len(accs):2d}  acc={np.mean(accs):.3f} ± {np.std(accs):.3f}  '\n",
    "          f'[{np.min(accs):.3f} - {np.max(accs):.3f}]')\n",
    "\n",
    "if errors:\n",
    "    print(f'\\nErrors:')\n",
    "    for k, v in errors.items():\n",
    "        print(f'  {k}: {v[\"error\"][:80]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy results to Drive for local download\n",
    "import shutil\n",
    "results_dir = os.path.join(FRAMEWORK_DIR, 'benchmarks', 'paper_results')\n",
    "drive_dest = '/content/drive/MyDrive/FL-EHDS-results'\n",
    "os.makedirs(drive_dest, exist_ok=True)\n",
    "for f in os.listdir(results_dir):\n",
    "    if f.endswith('.json'):\n",
    "        shutil.copy2(os.path.join(results_dir, f), drive_dest)\n",
    "        print(f'Copied: {f}')\n",
    "print(f'\\nResults saved to: {drive_dest}')\n",
    "print('Download from Google Drive to local machine, then run:')\n",
    "print('  python -m benchmarks.run_paper_experiments --only output')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
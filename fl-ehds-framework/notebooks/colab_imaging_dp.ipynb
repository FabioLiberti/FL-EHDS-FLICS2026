{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FL-EHDS: Imaging DP Experiments on Colab\n",
    "\n",
    "Runs Differential Privacy evaluation on imaging datasets (Chest X-Ray, Brain Tumor, Skin Cancer).\n",
    "\n",
    "**Setup:** Runtime > Change runtime type > **T4 GPU**\n",
    "\n",
    "**Experiments:** 3 algos × 3 datasets × 4 DP levels × 3 seeds = 108 experiments\n",
    "\n",
    "**Checkpoint:** Saved to Google Drive after every round (~1-2 min granularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for persistent checkpoint storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create persistent output directory on Drive\n",
    "import os\n",
    "DRIVE_OUTPUT = '/content/drive/MyDrive/FL-EHDS-FLICS2026/colab_results'\n",
    "os.makedirs(DRIVE_OUTPUT, exist_ok=True)\n",
    "print(f'Drive output: {DRIVE_OUTPUT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check GPU\nimport torch\nprint(f'PyTorch: {torch.__version__}')\nprint(f'CUDA available: {torch.cuda.is_available()}')\nif torch.cuda.is_available():\n    print(f'GPU: {torch.cuda.get_device_name(0)}')\n    props = torch.cuda.get_device_properties(0)\n    mem = getattr(props, 'total_memory', None) or getattr(props, 'total_mem', 0)\n    print(f'Memory: {mem / 1e9:.1f} GB')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/FabioLiberti/FL-EHDS-FLICS2026.git /content/FL-EHDS-FLICS2026\n",
    "%cd /content/FL-EHDS-FLICS2026/fl-ehds-framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install minimal dependencies (most already in Colab)\n",
    "!pip install -q scikit-learn scipy tqdm Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup Kaggle API\n# Upgrade kaggle to support API token auth\n!pip install -q --upgrade kaggle\n\nimport os\nos.environ['KAGGLE_API_TOKEN'] = 'KGAT_edd561c1bc682c9ad06930bacd164431'\n\n# Verify authentication\n!kaggle datasets list -s \"chest-xray\" --max-size 1 2>&1 | head -3\nprint('Kaggle auth OK')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Download Chest X-Ray Pneumonia (~2.3 GB)\n",
    "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia -p data/\n",
    "!unzip -q data/chest-xray-pneumonia.zip -d data/chest_xray_temp\n",
    "\n",
    "# Fix nested directory structure\n",
    "import shutil\n",
    "if os.path.exists('data/chest_xray_temp/chest_xray'):\n",
    "    # Move contents up one level\n",
    "    for item in ['train', 'test', 'val']:\n",
    "        src = f'data/chest_xray_temp/chest_xray/{item}'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, f'data/chest_xray/{item}')\n",
    "    # Also check top level\n",
    "    for item in ['train', 'test', 'val']:\n",
    "        src = f'data/chest_xray_temp/{item}'\n",
    "        if os.path.exists(src) and not os.path.exists(f'data/chest_xray/{item}'):\n",
    "            shutil.move(src, f'data/chest_xray/{item}')\n",
    "else:\n",
    "    shutil.move('data/chest_xray_temp', 'data/chest_xray')\n",
    "\n",
    "# Cleanup\n",
    "shutil.rmtree('data/chest_xray_temp', ignore_errors=True)\n",
    "os.remove('data/chest-xray-pneumonia.zip') if os.path.exists('data/chest-xray-pneumonia.zip') else None\n",
    "\n",
    "# Remove macOS junk\n",
    "shutil.rmtree('data/chest_xray/__MACOSX', ignore_errors=True)\n",
    "\n",
    "print('Chest X-Ray ready:')\n",
    "!find data/chest_xray -name '*.jpeg' -o -name '*.jpg' -o -name '*.png' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Download Skin Cancer (~325 MB)\n",
    "!kaggle datasets download -d fanconic/skin-cancer-malignant-vs-benign -p data/\n",
    "!unzip -q data/skin-cancer-malignant-vs-benign.zip -d \"data/Skin Cancer\"\n",
    "!rm -f data/skin-cancer-malignant-vs-benign.zip\n",
    "\n",
    "print('Skin Cancer ready:')\n",
    "!find \"data/Skin Cancer\" -name '*.jpg' -o -name '*.jpeg' -o -name '*.png' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Download Brain Tumor (~250 MB)\n",
    "!kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset -p data/\n",
    "!unzip -q data/brain-tumor-mri-dataset.zip -d data/Brain_Tumor_temp\n",
    "\n",
    "# Fix structure: might have nested directories\n",
    "import glob\n",
    "\n",
    "# Find where the class folders are (glioma, meningioma, pituitary, notumor/healthy)\n",
    "os.makedirs('data/Brain_Tumor', exist_ok=True)\n",
    "\n",
    "# Check common structures\n",
    "for root, dirs, files in os.walk('data/Brain_Tumor_temp'):\n",
    "    for d in dirs:\n",
    "        d_lower = d.lower()\n",
    "        if d_lower in ['glioma', 'meningioma', 'pituitary', 'notumor', 'no_tumor', 'healthy']:\n",
    "            target = 'healthy' if d_lower in ['notumor', 'no_tumor'] else d_lower\n",
    "            src = os.path.join(root, d)\n",
    "            dst = f'data/Brain_Tumor/{target}'\n",
    "            if not os.path.exists(dst):\n",
    "                shutil.move(src, dst)\n",
    "            else:\n",
    "                # Merge into existing\n",
    "                for f in os.listdir(src):\n",
    "                    shutil.move(os.path.join(src, f), os.path.join(dst, f))\n",
    "\n",
    "# If Training/Testing split structure, merge them\n",
    "for split_dir in ['Training', 'Testing']:\n",
    "    split_path = f'data/Brain_Tumor_temp/{split_dir}'\n",
    "    if os.path.exists(split_path):\n",
    "        for cls_dir in os.listdir(split_path):\n",
    "            cls_lower = cls_dir.lower()\n",
    "            target = 'healthy' if cls_lower in ['notumor', 'no_tumor'] else cls_lower\n",
    "            src = os.path.join(split_path, cls_dir)\n",
    "            dst = f'data/Brain_Tumor/{target}'\n",
    "            os.makedirs(dst, exist_ok=True)\n",
    "            if os.path.isdir(src):\n",
    "                for f in os.listdir(src):\n",
    "                    src_f = os.path.join(src, f)\n",
    "                    dst_f = os.path.join(dst, f)\n",
    "                    if not os.path.exists(dst_f):\n",
    "                        shutil.move(src_f, dst_f)\n",
    "\n",
    "shutil.rmtree('data/Brain_Tumor_temp', ignore_errors=True)\n",
    "os.remove('data/brain-tumor-mri-dataset.zip') if os.path.exists('data/brain-tumor-mri-dataset.zip') else None\n",
    "\n",
    "print('Brain Tumor ready:')\n",
    "!find data/Brain_Tumor -name '*.jpg' -o -name '*.jpeg' -o -name '*.png' | wc -l\n",
    "!ls data/Brain_Tumor/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all datasets\n",
    "print('=== Dataset Summary ===')\n",
    "for ds_name, ds_path in [('Chest X-Ray', 'data/chest_xray'), \n",
    "                          ('Skin Cancer', 'data/Skin Cancer'),\n",
    "                          ('Brain Tumor', 'data/Brain_Tumor')]:\n",
    "    count = sum(1 for _ in glob.iglob(f'{ds_path}/**/*.*', recursive=True) \n",
    "                if _.lower().endswith(('.jpg', '.jpeg', '.png')))\n",
    "    subdirs = [d for d in os.listdir(ds_path) if os.path.isdir(os.path.join(ds_path, d))]\n",
    "    print(f'  {ds_name:15s}: {count:5d} images, classes: {subdirs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Patch Script for Colab + Drive Checkpoint\n",
    "\n",
    "Redirect checkpoint output to Google Drive for persistence across sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content/FL-EHDS-FLICS2026/fl-ehds-framework')\n",
    "\n",
    "# Patch the script to save checkpoints to Google Drive\n",
    "import benchmarks.run_imaging_dp as dp_module\n",
    "from pathlib import Path\n",
    "\n",
    "# Override output directory to Google Drive\n",
    "dp_module.OUTPUT_DIR = Path(DRIVE_OUTPUT)\n",
    "print(f'Checkpoint directory: {dp_module.OUTPUT_DIR}')\n",
    "print(f'Checkpoint file: {dp_module.OUTPUT_DIR / dp_module.CHECKPOINT_FILE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick Validation (Optional)\n",
    "\n",
    "Run a quick 3-round test to verify everything works before the full run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick validation: 1 algo x 1 dataset x 1 epsilon x 1 seed x 3 rounds\n",
    "# Should complete in ~2-3 minutes\n",
    "!cd /content/FL-EHDS-FLICS2026/fl-ehds-framework && \\\n",
    "  python -c \"\n",
    "import sys, os\n",
    "sys.path.insert(0, '.')\n",
    "os.environ['IMAGING_DP_OUTPUT'] = '$DRIVE_OUTPUT'\n",
    "\n",
    "from benchmarks.run_imaging_dp import *\n",
    "from pathlib import Path\n",
    "\n",
    "# Quick single test\n",
    "config = {**IMAGING_CONFIG, 'num_rounds': 3, 'local_epochs': 1}\n",
    "es_config = {'enabled': False}\n",
    "\n",
    "print('Quick validation: chest_xray / FedAvg / eps=10 / seed=42 / 3 rounds')\n",
    "result = run_single_imaging(\n",
    "    ds_name='chest_xray',\n",
    "    data_dir=str(Path('.') / 'data' / 'chest_xray'),\n",
    "    algorithm='FedAvg',\n",
    "    dp_epsilon=10,\n",
    "    seed=42,\n",
    "    config=config,\n",
    "    es_config=es_config,\n",
    "    exp_idx=1, total_exps=1,\n",
    ")\n",
    "print(f'Result: {result[\\\"best_metrics\\\"]}')\n",
    "print('Validation OK!')\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Full DP Experiments\n",
    "\n",
    "**108 experiments** = 3 algos (FedAvg, Ditto, HPFL) × 3 datasets × 4 DP levels (No-DP, eps=1, 5, 10) × 3 seeds\n",
    "\n",
    "Checkpoint saved to Google Drive after **every round** (~1-2 min).\n",
    "\n",
    "If the session disconnects, re-run this cell — it auto-resumes from the last checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Full DP experiment run with checkpoint on Google Drive\n",
    "# Auto-resumes if session disconnects\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Create a wrapper script that patches OUTPUT_DIR before running\n",
    "wrapper_code = f'''\n",
    "import sys, os\n",
    "sys.path.insert(0, '/content/FL-EHDS-FLICS2026/fl-ehds-framework')\n",
    "os.chdir('/content/FL-EHDS-FLICS2026/fl-ehds-framework')\n",
    "\n",
    "# Patch OUTPUT_DIR to Google Drive before importing main()\n",
    "import benchmarks.run_imaging_dp as dp_mod\n",
    "from pathlib import Path\n",
    "dp_mod.OUTPUT_DIR = Path(\"{DRIVE_OUTPUT}\")\n",
    "\n",
    "# Patch sys.argv for argparse\n",
    "sys.argv = [\"run_imaging_dp.py\"]\n",
    "\n",
    "# Run\n",
    "dp_mod.main()\n",
    "'''\n",
    "\n",
    "with open('/tmp/run_dp.py', 'w') as f:\n",
    "    f.write(wrapper_code)\n",
    "\n",
    "!python /tmp/run_dp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5b. Alternative: Run One Dataset at a Time\n",
    "\n",
    "If session time is limited, run one dataset per session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only Chest X-Ray (36 experiments, ~2-3h on T4)\n",
    "# Change to Brain_Tumor or Skin_Cancer as needed\n",
    "DATASET = \"chest_xray\"  # Options: chest_xray, Brain_Tumor, Skin_Cancer\n",
    "\n",
    "wrapper_code = f'''\n",
    "import sys, os\n",
    "sys.path.insert(0, '/content/FL-EHDS-FLICS2026/fl-ehds-framework')\n",
    "os.chdir('/content/FL-EHDS-FLICS2026/fl-ehds-framework')\n",
    "\n",
    "import benchmarks.run_imaging_dp as dp_mod\n",
    "from pathlib import Path\n",
    "dp_mod.OUTPUT_DIR = Path(\"{DRIVE_OUTPUT}\")\n",
    "\n",
    "sys.argv = [\"run_imaging_dp.py\", \"--dataset\", \"{DATASET}\"]\n",
    "dp_mod.main()\n",
    "'''\n",
    "\n",
    "with open('/tmp/run_dp_single.py', 'w') as f:\n",
    "    f.write(wrapper_code)\n",
    "\n",
    "!python /tmp/run_dp_single.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Check Progress & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check checkpoint status\n",
    "import json\n",
    "\n",
    "ckpt_path = f'{DRIVE_OUTPUT}/checkpoint_imaging_dp.json'\n",
    "if os.path.exists(ckpt_path):\n",
    "    with open(ckpt_path) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    completed = data.get('completed', {})\n",
    "    in_progress = data.get('in_progress', {})\n",
    "    total = data.get('metadata', {}).get('total_experiments', '?')\n",
    "    \n",
    "    n_ok = sum(1 for v in completed.values() if 'error' not in v)\n",
    "    n_err = sum(1 for v in completed.values() if 'error' in v)\n",
    "    \n",
    "    print(f'Completed: {n_ok}/{total} (errors: {n_err})')\n",
    "    \n",
    "    if in_progress:\n",
    "        print(f'In progress: {in_progress.get(\"key\", \"?\")} '\n",
    "              f'round {in_progress.get(\"round\", \"?\")}/{in_progress.get(\"total_rounds\", \"?\")}')\n",
    "    \n",
    "    # Summary table\n",
    "    import numpy as np\n",
    "    print(f'\\n{\"Dataset\":<14} {\"Algorithm\":<10} {\"No-DP\":>8} {\"eps=1\":>8} {\"eps=5\":>8} {\"eps=10\":>8}')\n",
    "    print('-' * 62)\n",
    "    \n",
    "    for ds in ['chest_xray', 'Brain_Tumor', 'Skin_Cancer']:\n",
    "        for algo in ['FedAvg', 'Ditto', 'HPFL']:\n",
    "            row = f'{ds:<14} {algo:<10}'\n",
    "            for eps in [None, 1, 5, 10]:\n",
    "                eps_str = f'eps{eps}' if eps else 'noDP'\n",
    "                accs = []\n",
    "                for seed in [42, 123, 456]:\n",
    "                    k = f'{ds}_{algo}_{eps_str}_s{seed}'\n",
    "                    r = completed.get(k, {})\n",
    "                    if 'error' not in r and r:\n",
    "                        accs.append(r.get('best_metrics', {}).get('accuracy', 0))\n",
    "                if accs:\n",
    "                    row += f' {100*np.mean(accs):>7.1f}%'\n",
    "                else:\n",
    "                    row += f' {\"--\":>8}'\n",
    "            print(row)\n",
    "else:\n",
    "    print('No checkpoint found yet.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download checkpoint JSON for local integration\n",
    "from google.colab import files\n",
    "\n",
    "ckpt_path = f'{DRIVE_OUTPUT}/checkpoint_imaging_dp.json'\n",
    "if os.path.exists(ckpt_path):\n",
    "    files.download(ckpt_path)\n",
    "    print(f'Downloaded: checkpoint_imaging_dp.json')\n",
    "    \n",
    "    # Also download log\n",
    "    log_path = f'{DRIVE_OUTPUT}/experiment_imaging_dp.log'\n",
    "    if os.path.exists(log_path):\n",
    "        files.download(log_path)\n",
    "else:\n",
    "    print('No checkpoint to download yet.')"
   ]
  }
 ]
}
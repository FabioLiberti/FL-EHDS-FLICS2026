{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FL-EHDS: Imaging DP Experiments on Colab\n",
    "\n",
    "Runs Differential Privacy evaluation on imaging datasets (Chest X-Ray, Brain Tumor, Skin Cancer).\n",
    "\n",
    "**Setup:** Runtime > Change runtime type > **T4 GPU**\n",
    "\n",
    "**Experiments:** 3 algos × 3 datasets × 4 DP levels × 3 seeds = 108 experiments\n",
    "\n",
    "**Checkpoint:** Saved to Google Drive after every round (~1-2 min granularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for persistent checkpoint storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create persistent output directory on Drive\n",
    "import os\n",
    "DRIVE_OUTPUT = '/content/drive/MyDrive/FL-EHDS-FLICS2026/colab_results'\n",
    "os.makedirs(DRIVE_OUTPUT, exist_ok=True)\n",
    "print(f'Drive output: {DRIVE_OUTPUT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check GPU\nimport torch\nprint(f'PyTorch: {torch.__version__}')\nprint(f'CUDA available: {torch.cuda.is_available()}')\nif torch.cuda.is_available():\n    print(f'GPU: {torch.cuda.get_device_name(0)}')\n    props = torch.cuda.get_device_properties(0)\n    mem = getattr(props, 'total_memory', None) or getattr(props, 'total_mem', 0)\n    print(f'Memory: {mem / 1e9:.1f} GB')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/FabioLiberti/FL-EHDS-FLICS2026.git /content/FL-EHDS-FLICS2026\n",
    "%cd /content/FL-EHDS-FLICS2026/fl-ehds-framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install minimal dependencies (most already in Colab)\n",
    "!pip install -q scikit-learn scipy tqdm Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup Kaggle API (using kagglehub - supports KGAT_ tokens)\n!pip install -q kagglehub\n\nimport os\nos.environ['KAGGLE_API_TOKEN'] = 'KGAT_edd561c1bc682c9ad06930bacd164431'\n\nimport kagglehub\nprint(f'kagglehub version: {kagglehub.__version__}')\nprint('Kaggle auth ready')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# Download Chest X-Ray Pneumonia (~2.3 GB)\nimport kagglehub, shutil, os\n\ncache_path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\nprint(f'Downloaded to cache: {cache_path}')\n\n# Copy to data/chest_xray with correct structure\nos.makedirs('data/chest_xray', exist_ok=True)\nfor item in ['train', 'test', 'val']:\n    src = os.path.join(cache_path, 'chest_xray', item)\n    if not os.path.exists(src):\n        src = os.path.join(cache_path, item)\n    dst = f'data/chest_xray/{item}'\n    if os.path.exists(src) and not os.path.exists(dst):\n        shutil.copytree(src, dst)\n        print(f'  Copied {item}')\n\n# Remove macOS junk\nshutil.rmtree('data/chest_xray/__MACOSX', ignore_errors=True)\n\nprint('Chest X-Ray ready:')\n!find data/chest_xray -name '*.jpeg' -o -name '*.jpg' -o -name '*.png' | wc -l"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# Download Skin Cancer (~325 MB)\ncache_path = kagglehub.dataset_download(\"fanconic/skin-cancer-malignant-vs-benign\")\nprint(f'Downloaded to cache: {cache_path}')\n\n# Copy to data/Skin Cancer\ndst = 'data/Skin Cancer'\nif not os.path.exists(dst):\n    shutil.copytree(cache_path, dst)\n\nprint('Skin Cancer ready:')\n!find \"data/Skin Cancer\" -name '*.jpg' -o -name '*.jpeg' -o -name '*.png' | wc -l"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# Download Brain Tumor (~250 MB)\nimport glob\n\ncache_path = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\nprint(f'Downloaded to cache: {cache_path}')\n\n# Copy classes to data/Brain_Tumor (merge Training/Testing if split)\nos.makedirs('data/Brain_Tumor', exist_ok=True)\n\nfor root, dirs, files in os.walk(cache_path):\n    for d in dirs:\n        d_lower = d.lower()\n        if d_lower in ['glioma', 'meningioma', 'pituitary', 'notumor', 'no_tumor', 'healthy']:\n            target = 'healthy' if d_lower in ['notumor', 'no_tumor'] else d_lower\n            src = os.path.join(root, d)\n            dst = f'data/Brain_Tumor/{target}'\n            if not os.path.exists(dst):\n                shutil.copytree(src, dst)\n            else:\n                for f in os.listdir(src):\n                    src_f = os.path.join(src, f)\n                    dst_f = os.path.join(dst, f)\n                    if os.path.isfile(src_f) and not os.path.exists(dst_f):\n                        shutil.copy2(src_f, dst_f)\n\nprint('Brain Tumor ready:')\n!find data/Brain_Tumor -name '*.jpg' -o -name '*.jpeg' -o -name '*.png' | wc -l\n!ls data/Brain_Tumor/"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all datasets\n",
    "print('=== Dataset Summary ===')\n",
    "for ds_name, ds_path in [('Chest X-Ray', 'data/chest_xray'), \n",
    "                          ('Skin Cancer', 'data/Skin Cancer'),\n",
    "                          ('Brain Tumor', 'data/Brain_Tumor')]:\n",
    "    count = sum(1 for _ in glob.iglob(f'{ds_path}/**/*.*', recursive=True) \n",
    "                if _.lower().endswith(('.jpg', '.jpeg', '.png')))\n",
    "    subdirs = [d for d in os.listdir(ds_path) if os.path.isdir(os.path.join(ds_path, d))]\n",
    "    print(f'  {ds_name:15s}: {count:5d} images, classes: {subdirs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Patch Script for Colab + Drive Checkpoint\n",
    "\n",
    "Redirect checkpoint output to Google Drive for persistence across sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content/FL-EHDS-FLICS2026/fl-ehds-framework')\n",
    "\n",
    "# Patch the script to save checkpoints to Google Drive\n",
    "import benchmarks.run_imaging_dp as dp_module\n",
    "from pathlib import Path\n",
    "\n",
    "# Override output directory to Google Drive\n",
    "dp_module.OUTPUT_DIR = Path(DRIVE_OUTPUT)\n",
    "print(f'Checkpoint directory: {dp_module.OUTPUT_DIR}')\n",
    "print(f'Checkpoint file: {dp_module.OUTPUT_DIR / dp_module.CHECKPOINT_FILE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick Validation (Optional)\n",
    "\n",
    "Run a quick 3-round test to verify everything works before the full run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Quick validation: 1 algo x 1 dataset x 1 epsilon x 1 seed x 3 rounds\n# Should complete in ~2-3 minutes\nimport sys, os\nsys.path.insert(0, '/content/FL-EHDS-FLICS2026/fl-ehds-framework')\nos.chdir('/content/FL-EHDS-FLICS2026/fl-ehds-framework')\n\nfrom benchmarks.run_imaging_dp import *\nfrom pathlib import Path\n\n# Quick single test\nconfig = {**IMAGING_CONFIG, 'num_rounds': 3, 'local_epochs': 1}\nes_config = {'enabled': False}\n\nprint('Quick validation: chest_xray / FedAvg / eps=10 / seed=42 / 3 rounds')\nresult = run_single_imaging(\n    ds_name='chest_xray',\n    data_dir=str(Path('.') / 'data' / 'chest_xray'),\n    algorithm='FedAvg',\n    dp_epsilon=10,\n    seed=42,\n    config=config,\n    es_config=es_config,\n    exp_idx=1, total_exps=1,\n)\nprint(f'Result: {result[\"best_metrics\"]}')\nprint('Validation OK!')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Full DP Experiments\n",
    "\n",
    "**108 experiments** = 3 algos (FedAvg, Ditto, HPFL) × 3 datasets × 4 DP levels (No-DP, eps=1, 5, 10) × 3 seeds\n",
    "\n",
    "Checkpoint saved to Google Drive after **every round** (~1-2 min).\n",
    "\n",
    "If the session disconnects, re-run this cell — it auto-resumes from the last checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Full DP experiment run with checkpoint on Google Drive\n",
    "# Auto-resumes if session disconnects\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Create a wrapper script that patches OUTPUT_DIR before running\n",
    "wrapper_code = f'''\n",
    "import sys, os\n",
    "sys.path.insert(0, '/content/FL-EHDS-FLICS2026/fl-ehds-framework')\n",
    "os.chdir('/content/FL-EHDS-FLICS2026/fl-ehds-framework')\n",
    "\n",
    "# Patch OUTPUT_DIR to Google Drive before importing main()\n",
    "import benchmarks.run_imaging_dp as dp_mod\n",
    "from pathlib import Path\n",
    "dp_mod.OUTPUT_DIR = Path(\"{DRIVE_OUTPUT}\")\n",
    "\n",
    "# Patch sys.argv for argparse\n",
    "sys.argv = [\"run_imaging_dp.py\"]\n",
    "\n",
    "# Run\n",
    "dp_mod.main()\n",
    "'''\n",
    "\n",
    "with open('/tmp/run_dp.py', 'w') as f:\n",
    "    f.write(wrapper_code)\n",
    "\n",
    "!python /tmp/run_dp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5b. Alternative: Run One Dataset at a Time\n",
    "\n",
    "If session time is limited, run one dataset per session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only Chest X-Ray (36 experiments, ~2-3h on T4)\n",
    "# Change to Brain_Tumor or Skin_Cancer as needed\n",
    "DATASET = \"chest_xray\"  # Options: chest_xray, Brain_Tumor, Skin_Cancer\n",
    "\n",
    "wrapper_code = f'''\n",
    "import sys, os\n",
    "sys.path.insert(0, '/content/FL-EHDS-FLICS2026/fl-ehds-framework')\n",
    "os.chdir('/content/FL-EHDS-FLICS2026/fl-ehds-framework')\n",
    "\n",
    "import benchmarks.run_imaging_dp as dp_mod\n",
    "from pathlib import Path\n",
    "dp_mod.OUTPUT_DIR = Path(\"{DRIVE_OUTPUT}\")\n",
    "\n",
    "sys.argv = [\"run_imaging_dp.py\", \"--dataset\", \"{DATASET}\"]\n",
    "dp_mod.main()\n",
    "'''\n",
    "\n",
    "with open('/tmp/run_dp_single.py', 'w') as f:\n",
    "    f.write(wrapper_code)\n",
    "\n",
    "!python /tmp/run_dp_single.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Check Progress & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check checkpoint status\n",
    "import json\n",
    "\n",
    "ckpt_path = f'{DRIVE_OUTPUT}/checkpoint_imaging_dp.json'\n",
    "if os.path.exists(ckpt_path):\n",
    "    with open(ckpt_path) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    completed = data.get('completed', {})\n",
    "    in_progress = data.get('in_progress', {})\n",
    "    total = data.get('metadata', {}).get('total_experiments', '?')\n",
    "    \n",
    "    n_ok = sum(1 for v in completed.values() if 'error' not in v)\n",
    "    n_err = sum(1 for v in completed.values() if 'error' in v)\n",
    "    \n",
    "    print(f'Completed: {n_ok}/{total} (errors: {n_err})')\n",
    "    \n",
    "    if in_progress:\n",
    "        print(f'In progress: {in_progress.get(\"key\", \"?\")} '\n",
    "              f'round {in_progress.get(\"round\", \"?\")}/{in_progress.get(\"total_rounds\", \"?\")}')\n",
    "    \n",
    "    # Summary table\n",
    "    import numpy as np\n",
    "    print(f'\\n{\"Dataset\":<14} {\"Algorithm\":<10} {\"No-DP\":>8} {\"eps=1\":>8} {\"eps=5\":>8} {\"eps=10\":>8}')\n",
    "    print('-' * 62)\n",
    "    \n",
    "    for ds in ['chest_xray', 'Brain_Tumor', 'Skin_Cancer']:\n",
    "        for algo in ['FedAvg', 'Ditto', 'HPFL']:\n",
    "            row = f'{ds:<14} {algo:<10}'\n",
    "            for eps in [None, 1, 5, 10]:\n",
    "                eps_str = f'eps{eps}' if eps else 'noDP'\n",
    "                accs = []\n",
    "                for seed in [42, 123, 456]:\n",
    "                    k = f'{ds}_{algo}_{eps_str}_s{seed}'\n",
    "                    r = completed.get(k, {})\n",
    "                    if 'error' not in r and r:\n",
    "                        accs.append(r.get('best_metrics', {}).get('accuracy', 0))\n",
    "                if accs:\n",
    "                    row += f' {100*np.mean(accs):>7.1f}%'\n",
    "                else:\n",
    "                    row += f' {\"--\":>8}'\n",
    "            print(row)\n",
    "else:\n",
    "    print('No checkpoint found yet.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download checkpoint JSON for local integration\n",
    "from google.colab import files\n",
    "\n",
    "ckpt_path = f'{DRIVE_OUTPUT}/checkpoint_imaging_dp.json'\n",
    "if os.path.exists(ckpt_path):\n",
    "    files.download(ckpt_path)\n",
    "    print(f'Downloaded: checkpoint_imaging_dp.json')\n",
    "    \n",
    "    # Also download log\n",
    "    log_path = f'{DRIVE_OUTPUT}/experiment_imaging_dp.log'\n",
    "    if os.path.exists(log_path):\n",
    "        files.download(log_path)\n",
    "else:\n",
    "    print('No checkpoint to download yet.')"
   ]
  }
 ]
}